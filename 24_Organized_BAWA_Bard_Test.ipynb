{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZadarX43/BAWA_SOURCE/blob/main/24_Organized_BAWA_Bard_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db2fd580",
      "metadata": {
        "id": "db2fd580"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2081407a",
      "metadata": {
        "id": "2081407a"
      },
      "outputs": [],
      "source": [
        "\n",
        "from xgboost import XGBClassifier\n",
        "import pandas as pd\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "dZJfRIOn-aYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fcad723-82f8-43cb-cd5e-2ff5f3d132b9"
      },
      "id": "dZJfRIOn-aYL",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n"
      ],
      "metadata": {
        "id": "Nj9hd9E9-DZ0"
      },
      "id": "Nj9hd9E9-DZ0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have mounted your Google Drive and the path to your files is set correctly\n",
        "path_to_files = '/content/drive/My Drive/'  # Update this with the correct path\n",
        "\n",
        "# Load each file into a DataFrame\n",
        "league_stats_df = pd.read_csv(path_to_files + \"europe-uefa-champions-league-league-2023-to-2024-stats.csv\")\n",
        "matches_df = pd.read_csv(path_to_files + \"europe-uefa-champions-league-matches-2023-to-2024-stats.csv\")\n",
        "players_df = pd.read_csv(path_to_files + \"europe-uefa-champions-league-players-2023-to-2024-stats.csv\")\n",
        "teams_df = pd.read_csv(path_to_files + \"europe-uefa-champions-league-teams-2023-to-2024-stats.csv\")\n",
        "\n",
        "# Display the first few rows of each DataFrame to verify\n",
        "print(league_stats_df.head())\n",
        "print(matches_df.head())\n",
        "print(players_df.head())\n",
        "print(teams_df.head())\n"
      ],
      "metadata": {
        "id": "7jfdA7Ci-FYs"
      },
      "id": "7jfdA7Ci-FYs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading\n",
        "Load the dataset from various sources."
      ],
      "metadata": {
        "id": "xOvj7kec-Pdf"
      },
      "id": "xOvj7kec-Pdf"
    },
    {
      "cell_type": "code",
      "source": [
        "Data Loading\n",
        "Load the dataset from various sources."
      ],
      "metadata": {
        "id": "Q1Plo-ut-Qw0"
      },
      "id": "Q1Plo-ut-Qw0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yWdzb8YR-Ri_"
      },
      "id": "yWdzb8YR-Ri_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6877c8e1",
      "metadata": {
        "id": "6877c8e1"
      },
      "source": [
        "## Automation Script for Loading Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f7cf264",
      "metadata": {
        "id": "4f7cf264"
      },
      "outputs": [],
      "source": [
        "\n",
        "# AUTOMATION SCRIPT FOR LOADING THE FILES\n",
        "# (Insert the automation script code here)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Function to load data for a single league\n",
        "def load_league_data(league_name, path_to_files):\n",
        "    data = {}\n",
        "    file_types = ['players', 'teams', 'matches', 'league']\n",
        "    for file_type in file_types:\n",
        "        filename = f\"{league_name}-{file_type}-2023-to-2024-stats.csv\"\n",
        "        data[file_type] = pd.read_csv(os.path.join(path_to_files, filename))\n",
        "    return data\n",
        "\n",
        "# Function to preprocess data (You'll fill in the details of preprocessing based on your needs)\n",
        "def preprocess_data(data):\n",
        "    # Example preprocessing steps:\n",
        "    # - Handle missing values\n",
        "    # - Feature engineering\n",
        "    # - Encode categorical variables\n",
        "    # - Normalize/standardize numerical variables\n",
        "    # Add your preprocessing steps here\n",
        "    return data\n",
        "\n",
        "# Function to merge dataframes (if needed)\n",
        "def merge_dataframes(players_df, teams_df, matches_df, league_stats_df):\n",
        "    # Example of merging\n",
        "    # You will need to adjust the merging logic based on how you want to combine your data\n",
        "    merged_df = pd.merge(matches_df, teams_df, on='team_key')\n",
        "    merged_df = pd.merge(merged_df, players_df, on='player_key')\n",
        "    return merged_df\n",
        "\n",
        "# Function to split the data into features and target\n",
        "def split_data(merged_df, target_column):\n",
        "    X = merged_df.drop(target_column, axis=1)\n",
        "    y = merged_df[target_column]\n",
        "    return X, y\n",
        "\n",
        "# Function to automate the process for all leagues\n",
        "def automate_process(path_to_files, leagues, target_column):\n",
        "    for league_name in leagues:\n",
        "        print(f\"Processing data for {league_name}...\")\n",
        "        data = load_league_data(league_name, path_to_files)\n",
        "        data = preprocess_data(data)\n",
        "        merged_df = merge_dataframes(**data)\n",
        "        X, y = split_data(merged_df, target_column)\n",
        "\n",
        "        # Split into training and test sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # You would add here your model training and saving logic\n",
        "        # ...\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    path_to_files = '/content/drive/My Drive/94_betting_model/'  # Update this with the correct path\n",
        "    leagues = [\n",
        "        'europe-uefa-europa-conference-league',\n",
        "        'england-fa-womens-super-league',\n",
        "        # Add all your league names here...\n",
        "    ]\n",
        "    target_column = 'FTR'  # Update this if your target variable is named differently\n",
        "\n",
        "    automate_process(path_to_files, leagues, target_column)"
      ],
      "metadata": {
        "id": "sz_n_HNvoGd0"
      },
      "id": "sz_n_HNvoGd0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT PROCESSING TO MERGE AND STREAMLINE VIA GPT"
      ],
      "metadata": {
        "id": "muIf9myvphks"
      },
      "id": "muIf9myvphks"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_and_preprocess(path, league_name):\n",
        "    # Load each dataset\n",
        "    team_stats = pd.read_csv(f'{path}{league_name}-teams-2023-to-2024-stats.csv')\n",
        "    player_stats = pd.read_csv(f'{path}{league_name}-players-2023-to-2024-stats.csv')\n",
        "    match_stats = pd.read_csv(f'{path}{league_name}-matches-2023-to-2024-stats.csv')\n",
        "    league_stats = pd.read_csv(f'{path}{league_name}-league-2023-to-2024-stats.csv')\n",
        "\n",
        "    # Preprocessing steps (as an example, this would be customized to your data)\n",
        "    # Merge the datasets on common columns (e.g., team name)\n",
        "    # merged_df = pd.merge(match_stats, team_stats, left_on='home_team_name', right_on='team_name')\n",
        "    # More preprocessing steps...\n",
        "\n",
        "    # Return the preprocessed dataframe\n",
        "    return merged_df\n",
        "\n",
        "def get_training_testing_features(preprocessed_df):\n",
        "    # Extracting the features and target from the preprocessed dataframe\n",
        "    features = preprocessed_df[['Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_team_goal_count',\n",
        "                                'away_team_goal_count', 'average_corners_per_match_pre_match',\n",
        "                                'average_cards_per_match_pre_match', 'odds_ft_home_team_win',\n",
        "                                'odds_ft_draw', 'odds_ft_away_team_win']]\n",
        "    target = preprocessed_df['result_column']  # Replace 'result_column' with the actual result column name\n",
        "\n",
        "    # Splitting the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def main():\n",
        "    path_to_files = '/content/drive/My Drive/94_betting_model/'\n",
        "    leagues = [\n",
        "        'europe-uefa-europa-conference-league',\n",
        "        'england-fa-womens-super-league',\n",
        "        # ... add other leagues as needed\n",
        "    ]\n",
        "\n",
        "    for league_name in leagues:\n",
        "        preprocessed_df = load_and_preprocess(path_to_files, league_name)\n",
        "        X_train, X_test, y_train, y_test = get_training_testing_features(preprocessed_df)\n",
        "\n",
        "        # Here, you can add your model training and evaluation\n",
        "        # model.fit(X_train, y_train)\n",
        "        # ...\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "2hRIzH6tp2W8"
      },
      "id": "2hRIzH6tp2W8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_and_preprocess_all_leagues(path, league_names):\n",
        "    all_leagues_data = []\n",
        "\n",
        "    for league_name in league_names:\n",
        "        # Load each dataset for the league\n",
        "        team_stats = pd.read_csv(f'{path}{league_name}-teams-2023-to-2024-stats.csv')\n",
        "        player_stats = pd.read_csv(f'{path}{league_name}-players-2023-to-2024-stats.csv')\n",
        "        match_stats = pd.read_csv(f'{path}{league_name}-matches-2023-to-2024-stats.csv')\n",
        "        league_stats = pd.read_csv(f'{path}{league_name}-league-2023-to-2024-stats.csv')\n",
        "\n",
        "        # Preprocessing steps for each league\n",
        "        # Example merge (customize as per your requirement)\n",
        "        merged_df = pd.merge(match_stats, team_stats, left_on='home_team_name', right_on='team_name', how='left')\n",
        "\n",
        "        # Add more preprocessing steps as needed\n",
        "        # ...\n",
        "\n",
        "        # Append the processed DataFrame to the list\n",
        "        all_leagues_data.append(merged_df)\n",
        "\n",
        "    # Concatenate all league data into one DataFrame\n",
        "    combined_df = pd.concat(all_leagues_data, ignore_index=True)\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "# List of league names\n",
        "league_names = ['europe-uefa-europa-league', 'england-premier-league', 'europe-uefa-champions-league', 'england-fa-womens-super-league', 'europe-uefa-europa-conference-league']  # Add any other leagues if needed\n",
        "\n",
        "# Replace with your actual file path\n",
        "path_to_files = '/content/drive/My Drive/94_betting_model/'\n",
        "\n",
        "# Load and preprocess data for all leagues\n",
        "combined_leagues_df = load_and_preprocess_all_leagues(path_to_files, league_names)"
      ],
      "metadata": {
        "id": "_mnHOrZCp_ml"
      },
      "id": "_mnHOrZCp_ml",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# Set your Google Drive path\n",
        "path_to_files = '/content/drive/My Drive/94_betting_model/'\n",
        "\n",
        "# Define your leagues\n",
        "leagues = [\n",
        "    'europe-uefa-europa-conference-league',\n",
        "    'england-fa-womens-super-league',\n",
        "    'england-premier-league',\n",
        "    'europe-uefa-europa-league',\n",
        "    'europe-uefa-champions-league',\n",
        "    # ... add other leagues as needed\n",
        "]\n",
        "\n",
        "# Define the preprocessing function\n",
        "def preprocess_data(df):\n",
        "    # Here, you would include steps such as:\n",
        "    # - Handling missing values\n",
        "    # - Feature engineering\n",
        "    # - Encoding categorical variables\n",
        "    # - Normalizing or standardizing features\n",
        "    # ... add your preprocessing steps\n",
        "    return df\n",
        "\n",
        "# Define the merging function\n",
        "def merge_dataframes(league_name):\n",
        "    # Load all related dataframes\n",
        "    players_df = pd.read_csv(f'{path_to_files}{league_name}-players-2023-to-2024-stats.csv')\n",
        "    teams_df = pd.read_csv(f'{path_to_files}{league_name}-teams-2023-to-2024-stats.csv')\n",
        "    matches_df = pd.read_csv(f'{path_to_files}{league_name}-matches-2023-to-2024-stats.csv')\n",
        "    league_stats_df = pd.read_csv(f'{path_to_files}{league_name}-league-2023-to-2024-stats.csv')\n",
        "\n",
        "    # Merge your dataframes in the way that aligns with your model needs\n",
        "    # Example:\n",
        "    # merged_df = pd.merge(matches_df, players_df, on='common_column')\n",
        "    # ... add your merge logic\n",
        "\n",
        "    return merged_df\n",
        "\n",
        "# Define the automation function\n",
        "def automate_process(leagues, target_column):\n",
        "    for league_name in leagues:\n",
        "        print(f'Processing data for {league_name}')\n",
        "\n",
        "        # Merge dataframes\n",
        "        merged_df = merge_dataframes(league_name)\n",
        "\n",
        "        # Preprocess data\n",
        "        processed_df = preprocess_data(merged_df)\n",
        "\n",
        "        # Split into features and target\n",
        "        X = processed_df.drop(target_column, axis=1)\n",
        "        y = processed_df[target_column]\n",
        "\n",
        "        # Split the data into training and test sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # At this point, you can add your model training and evaluation code\n",
        "        # ...\n",
        "\n",
        "# Call the function\n",
        "automate_process(leagues, 'target_column_name')  # Replace 'target_column_name' with the actual name of your target column\n"
      ],
      "metadata": {
        "id": "0KMticE-pfP_"
      },
      "id": "0KMticE-pfP_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List the contents of the main Google Drive directory\n",
        "os.listdir('/content/drive/My Drive/94_betting_model')\n"
      ],
      "metadata": {
        "id": "SCBejwa5-Vbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e876fdc-e2a1-455b-9f50-9b98020a1805"
      },
      "id": "SCBejwa5-Vbs",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['feature_names.txt',\n",
              " '94_betting_model.pkl',\n",
              " 'cleaned_matches_data_df.csv',\n",
              " 'training_data.csv',\n",
              " 'combined_leagues_data.csv',\n",
              " 'predictions_2.csv',\n",
              " 'matches_on_specific_dates.csv',\n",
              " 'predictions.csv',\n",
              " 'predictions3.csv',\n",
              " 'BAWA_2_2024',\n",
              " 'feature_names.gdoc',\n",
              " 'Copy of feature_names.gdoc',\n",
              " 'Copy of feature_names.txt',\n",
              " 'Copy of 94_betting_model.pkl',\n",
              " 'Copy of predictions.csv',\n",
              " 'Copy of combined_leagues_data.csv',\n",
              " 'Copy of predictions3.csv',\n",
              " 'Copy of cleaned_matches_data_df.csv',\n",
              " 'Copy of matches_on_specific_dates.csv',\n",
              " 'Copy of training_data.csv',\n",
              " 'Copy of predictions_2.csv',\n",
              " 'europe-uefa-champions-league-league-2023-to-2024-stats (1).csv',\n",
              " 'europe-uefa-champions-league-matches-2023-to-2024-stats (1).csv',\n",
              " 'europe-uefa-champions-league-teams-2023-to-2024-stats (1).csv',\n",
              " 'europe-uefa-champions-league-players-2023-to-2024-stats (1).csv',\n",
              " 'europe-uefa-europa-league-league-2023-to-2024-stats (1).csv',\n",
              " 'europe-uefa-europa-league-matches-2023-to-2024-stats (1).csv',\n",
              " 'europe-uefa-europa-league-teams-2023-to-2024-stats (1).csv',\n",
              " 'europe-uefa-europa-league-players-2023-to-2024-stats (1).csv',\n",
              " 'europe-uefa-europa-conference-league-league-2023-to-2024-stats (1).csv',\n",
              " 'europe-uefa-europa-conference-league-matches-2023-to-2024-stats (1).csv',\n",
              " 'europe-uefa-europa-conference-league-teams-2023-to-2024-stats (1).csv',\n",
              " 'europe-uefa-europa-conference-league-players-2023-to-2024-stats (1).csv',\n",
              " 'england-premier-league-league-2023-to-2024-stats (2).csv',\n",
              " 'england-premier-league-matches-2023-to-2024-stats (2).csv',\n",
              " 'england-premier-league-teams-2023-to-2024-stats (2).csv',\n",
              " 'england-premier-league-players-2023-to-2024-stats (2).csv',\n",
              " 'spain-la-liga-league-2023-to-2024-stats (1).csv',\n",
              " 'spain-la-liga-matches-2023-to-2024-stats (1).csv',\n",
              " 'spain-la-liga-teams-2023-to-2024-stats (1).csv',\n",
              " 'spain-la-liga-players-2023-to-2024-stats (1).csv',\n",
              " 'germany-bundesliga-league-2023-to-2024-stats (1).csv',\n",
              " 'germany-bundesliga-matches-2023-to-2024-stats (1).csv',\n",
              " 'germany-bundesliga-teams-2023-to-2024-stats (1).csv',\n",
              " 'germany-bundesliga-players-2023-to-2024-stats (1).csv',\n",
              " 'france-ligue-1-league-2023-to-2024-stats (1).csv',\n",
              " 'france-ligue-1-matches-2023-to-2024-stats (1).csv',\n",
              " 'france-ligue-1-teams-2023-to-2024-stats (1).csv',\n",
              " 'france-ligue-1-players-2023-to-2024-stats (1).csv',\n",
              " 'portugal-liga-nos-league-2023-to-2024-stats (1).csv',\n",
              " 'portugal-liga-nos-matches-2023-to-2024-stats (1).csv',\n",
              " 'portugal-liga-nos-teams-2023-to-2024-stats (1).csv',\n",
              " 'portugal-liga-nos-players-2023-to-2024-stats (1).csv',\n",
              " 'scotland-premiership-league-2023-to-2024-stats (1).csv',\n",
              " 'scotland-premiership-matches-2023-to-2024-stats (1).csv',\n",
              " 'scotland-premiership-teams-2023-to-2024-stats (1).csv',\n",
              " 'scotland-premiership-players-2023-to-2024-stats (1).csv',\n",
              " 'italy-serie-a-league-2023-to-2024-stats (1).csv',\n",
              " 'italy-serie-a-matches-2023-to-2024-stats (1).csv',\n",
              " 'italy-serie-a-teams-2023-to-2024-stats (1).csv',\n",
              " 'italy-serie-a-players-2023-to-2024-stats (1).csv',\n",
              " 'england-championship-league-2023-to-2024-stats.csv',\n",
              " 'england-championship-matches-2023-to-2024-stats.csv',\n",
              " 'england-championship-teams-2023-to-2024-stats.csv',\n",
              " 'england-championship-players-2023-to-2024-stats.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess(path, league_name):\n",
        "    # Load each dataset\n",
        "    team_stats = pd.read_csv(f'{path}{league_name}-teams-2023-to-2024-stats (1).csv')\n",
        "    player_stats = pd.read_csv(f'{path}{league_name}-players-2023-to-2024-stats (1).csv')\n",
        "    match_stats = pd.read_csv(f'{path}{league_name}-matches-2023-to-2024-stats (1).csv')\n",
        "    league_stats = pd.read_csv(f'{path}{league_name}-league-2023-to-2024-stats (1).csv')\n",
        "\n",
        "    # Preprocessing steps (you need to customize this to your data)\n",
        "    # For example, if you want to merge match_stats and team_stats on team names:\n",
        "    # Ensure that the team names match exactly in both dataframes, or map them to be the same.\n",
        "    merged_df = pd.merge(match_stats, team_stats, left_on='home_team_name', right_on='team_name', how='left')\n",
        "\n",
        "    # Add more preprocessing steps as needed, such as merging with player_stats and league_stats\n",
        "    # and handle missing values, create new features, etc.\n",
        "\n",
        "    # Assuming merged_df is your final merged DataFrame after all preprocessing\n",
        "    return merged_df\n"
      ],
      "metadata": {
        "id": "zpiRB9gR-Vma"
      },
      "id": "zpiRB9gR-Vma",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_and_preprocess_all_leagues(path, league_names):\n",
        "    all_leagues_data = []\n",
        "\n",
        "    for league_name in league_names:\n",
        "        # Load each dataset for the league\n",
        "        team_stats = pd.read_csv(f'{path}{league_name}-teams-2023-to-2024-stats (1).csv')\n",
        "        player_stats = pd.read_csv(f'{path}{league_name}-players-2023-to-2024-stats (1).csv')\n",
        "        match_stats = pd.read_csv(f'{path}{league_name}-matches-2023-to-2024-stats (1).csv')\n",
        "        league_stats = pd.read_csv(f'{path}{league_name}-league-2023-to-2024-stats (1).csv')\n",
        "\n",
        "        # Preprocessing steps for each league\n",
        "        # Example merge (customize as per your requirement)\n",
        "        merged_df = pd.merge(match_stats, team_stats, left_on='home_team_name', right_on='team_name', how='left')\n",
        "\n",
        "        # Add more preprocessing steps as needed\n",
        "        # ...\n",
        "\n",
        "        # Append the processed DataFrame to the list\n",
        "        all_leagues_data.append(merged_df)\n",
        "\n",
        "    # Concatenate all league data into one DataFrame\n",
        "    combined_df = pd.concat(all_leagues_data, ignore_index=True)\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "# List of league names\n",
        "league_names = ['europe-uefa-europa-league', 'england-premier-league', 'europe-uefa-champions-league', 'england-fa-womens-super-league', 'europe-uefa-europa-conference-league']  # Add any other leagues if needed\n",
        "\n",
        "# Replace with your actual file path\n",
        "path_to_files = '/content/drive/My Drive/94_betting_model/'\n",
        "\n",
        "# Load and preprocess data for all leagues\n",
        "combined_leagues_df = load_and_preprocess_all_leagues(path_to_files, league_names)\n"
      ],
      "metadata": {
        "id": "ECbZD7TT-n7Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "5fce2f3b-0f98-49ae-b616-d80f2ab2251d"
      },
      "id": "ECbZD7TT-n7Z",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/94_betting_model/england-premier-league-teams-2023-to-2024-stats (1).csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-052b17f80e77>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Load and preprocess data for all leagues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mcombined_leagues_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_preprocess_all_leagues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleague_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-052b17f80e77>\u001b[0m in \u001b[0;36mload_and_preprocess_all_leagues\u001b[0;34m(path, league_names)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mleague_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mleague_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Load each dataset for the league\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mteam_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{path}{league_name}-teams-2023-to-2024-stats (1).csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mplayer_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{path}{league_name}-players-2023-to-2024-stats (1).csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmatch_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{path}{league_name}-matches-2023-to-2024-stats (1).csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/94_betting_model/england-premier-league-teams-2023-to-2024-stats (1).csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the combined_leagues_df DataFrame to a CSV file\n",
        "combined_leagues_df.to_csv('/content/drive/My Drive/94_betting_model/combined_leagues_data.csv', index=False)\n",
        "\n",
        "# Extracting specified training features\n",
        "selected_features = ['Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_team_goal_count', 'away_team_goal_count', 'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match', 'odds_ft_home_team_win', 'odds_ft_draw', 'odds_ft_away_team_win']\n",
        "training_data = combined_leagues_df[selected_features]\n",
        "\n",
        "# Optionally, you can also export the extracted training data\n",
        "training_data.to_csv('/content/drive/My Drive/94_betting_model/training_data.csv', index=False)"
      ],
      "metadata": {
        "id": "XUzhAkPi-rz0"
      },
      "id": "XUzhAkPi-rz0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install unidecode\n",
        "!pip install unidecode\n",
        "\n",
        "# Import unidecode\n",
        "import unidecode\n",
        "\n",
        "# Apply unidecode to standardize player names\n",
        "combined_player_stats['full_name'] = combined_player_stats['full_name'].apply(unidecode.unidecode)\n",
        "\n",
        "# Check the changes\n",
        "print(combined_player_stats.head())"
      ],
      "metadata": {
        "id": "fr-Smb04Aqzq"
      },
      "id": "fr-Smb04Aqzq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping specified columns\n",
        "columns_to_drop = ['attendance', 'booked_over05_percentage_overall',\n",
        "                   'booked_over05_percentage_percentile_overall',\n",
        "                   'shirt_number', 'annual_salary_gbp', 'annual_salary_usd']\n",
        "\n",
        "combined_player_stats.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "cleaned_matches_data_df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "\n",
        "# Checking the DataFrame after dropping the columns\n",
        "print(combined_player_stats.head())\n",
        "print(cleaned_matches_data_df.head())"
      ],
      "metadata": {
        "id": "pcE9i-QLAw8T"
      },
      "id": "pcE9i-QLAw8T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hwDMwoSjXwYC"
      },
      "id": "hwDMwoSjXwYC"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8zLliyOIXwbG"
      },
      "id": "8zLliyOIXwbG"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6aQKpiNEXwd5"
      },
      "id": "6aQKpiNEXwd5"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "80esz8_cXwgl"
      },
      "id": "80esz8_cXwgl"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "cleaned_teams_path = 'cleaned_teams_head_to_head.csv'\n",
        "cleaned_matches_path = 'cleaned_matches.csv'\n",
        "\n",
        "# Read the data into pandas dataframes\n",
        "cleaned_teams_data = pd.read_csv(cleaned_teams_path)\n",
        "cleaned_matches_data = pd.read_csv(cleaned_matches_path)\n",
        "\n",
        "# Display the first few rows to check the features\n",
        "print(cleaned_teams_data.head())\n",
        "print(cleaned_matches_data.head())\n",
        "\n",
        "# Example code to check for missing values\n",
        "print(cleaned_teams_data.isnull().sum())\n",
        "print(cleaned_matches_data.isnull().sum())\n",
        "\n",
        "# Fill missing values or drop rows/columns\n",
        "# cleaned_teams_data.fillna(0, inplace=True)  # Example to fill missing values with 0\n",
        "# cleaned_matches_data.dropna(inplace=True)   # Example to drop rows with missing values\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Replace 'path_to_your_file.csv' with the actual file path\n",
        "cleaned_matches_data_df = pd.read_csv('/content/cleaned_teams_head_to_head.csv')\n",
        "\n",
        "# Aggregating player stats by team and season\n",
        "aggregation_methods = {\n",
        "    'goals_per_90_overall': 'mean',\n",
        "    'assists_per_90_overall': 'mean',\n",
        "    'average_rating_overall': 'mean',\n",
        "    'clean_sheets_overall': 'sum',\n",
        "    'goals_overall': 'sum',\n",
        "    'assists_overall': 'sum',\n",
        "    'appearances_overall': 'sum',\n",
        "    'minutes_played_overall': 'sum',\n",
        "    'yellow_cards_overall': 'sum',\n",
        "    'red_cards_overall': 'sum',\n",
        "    'tackles_per_90_overall': 'sum',\n",
        "    'xg_per_90_overall': 'sum',\n",
        "    'xa_per_90_overall': 'sum',\n",
        "    'npxg_per_90_overall': 'sum',\n",
        "    'interceptions_per_90_overall': 'sum',\n",
        "    'distance_travelled_per_90_overall': 'sum',\n",
        "    'aerial_duels_won_per_90_overall': 'sum',\n",
        "    'shots_on_target_per_90_overall': 'sum',\n",
        "    'shot_conversion_rate_overall': 'sum',\n",
        "    'key_passes_per_90_overall': 'sum',\n",
        "    'through_passes_per_90_overall': 'sum',\n",
        "    'chances_created_per_90_overall': 'sum',\n",
        "    'dribbles_per_90_overall': 'sum',\n",
        "    'dribbles_successful_percentage_overall': 'sum',\n",
        "    'passes_per_90_overall': 'sum',\n",
        "    'pass_completion_rate_overall': 'sum',\n",
        "    'full_name': 'first',\n",
        "    'age': 'first',\n",
        "    'position': 'first',\n",
        "    'league': 'first'\n",
        "    # Note: Removed 'Current Club' and 'season' as they are already included as part of the groupby\n",
        "}\n",
        "\n",
        "aggregated_player_stats = extracted_features_df.groupby(['Current Club', 'season']).agg(aggregation_methods).reset_index()\n",
        "\n",
        "# Assuming 'team_name' in cleaned_teams_data matches 'Current Club' in aggregated_player_stats\n",
        "merged_team_player_stats = pd.merge(\n",
        "    cleaned_teams_data,\n",
        "    aggregated_player_stats,\n",
        "    left_on=['team_name', 'season'],\n",
        "    right_on=['Current Club', 'season'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Assuming 'home_team_name' and 'away_team_name' in cleaned_matches_data_df\n",
        "final_dataset = pd.merge(\n",
        "    cleaned_matches_data_df,\n",
        "    merged_team_player_stats,\n",
        "    left_on=['common_name', 'season'],\n",
        "    right_on=['team_name', 'season'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(cleaned_matches_data_df.columns)\n",
        "\n",
        "# Specify the file path and name for your downloaded file\n",
        "download_path = '/content/merged_team_player_stats.csv'\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "merged_team_player_stats.to_csv(download_path, index=False)\n",
        "\n",
        "# Code to download the file to your local system\n",
        "from google.colab import files\n",
        "files.download(download_path)\n",
        "\n",
        "cleaned_matches_data_df = pd.read_csv('/content/cleaned_matches (2).csv')\n",
        "print(cleaned_matches_data_df.columns)\n",
        "\n",
        "# Replace 'path_to_your_file' with the actual path of your CSV file\n",
        "cleaned_matches_data_df = pd.read_csv('/content/cleaned_matches (2).csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(cleaned_matches_data_df.head())\n",
        "\n",
        "# Check column names\n",
        "print(cleaned_matches_data_df.columns)\n",
        "\n",
        "'cleaned_matches_data_df' in locals() or 'cleaned_matches_data_df' in globals()\n",
        "\n",
        "print(cleaned_matches_data_df.columns)\n",
        "print(merged_team_player_stats.columns)\n",
        "\n",
        "cleaned_matches_data_df['season'] = pd.to_datetime(cleaned_matches_data_df['date_GMT']).dt.year\n",
        "\n",
        "# Convert 'season' to string in both DataFrames\n",
        "cleaned_matches_data_df['season'] = cleaned_matches_data_df['season'].astype(str)\n",
        "merged_team_player_stats['season'] = merged_team_player_stats['season'].astype(str)\n",
        "\n",
        "# Merge considering 'common_name' as the home team\n",
        "final_dataset_home = pd.merge(\n",
        "    cleaned_matches_data_df,\n",
        "    merged_team_player_stats,\n",
        "    left_on=['home_team_name', 'season'],\n",
        "    right_on=['common_name', 'season'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Merge considering 'common_name' as the away team\n",
        "final_dataset_away = pd.merge(\n",
        "    cleaned_matches_data_df,\n",
        "    merged_team_player_stats,\n",
        "    left_on=['away_team_name', 'season'],\n",
        "    right_on=['common_name', 'season'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Validate the merged data\n",
        "print(final_dataset_home.head())\n",
        "print(final_dataset_away.head())\n",
        "\n",
        "# Example: Check unique team names in both DataFrames\n",
        "print(cleaned_matches_data_df['home_team_name'].unique())\n",
        "print(merged_team_player_stats['common_name'].unique())\n",
        "\n",
        "# Extracting team names from the match data\n",
        "team_names_match_data = set(cleaned_matches_data_df['home_team_name'].tolist() + cleaned_matches_data_df['away_team_name'].tolist())\n",
        "\n",
        "# Extracting team names from the player stats data\n",
        "team_names_player_stats = set(merged_team_player_stats['common_name'].tolist())\n",
        "\n",
        "# Now proceed to compare the lists and find discrepancies\n",
        "non_matching_names_match_data = team_names_match_data - team_names_player_stats\n",
        "non_matching_names_player_stats = team_names_player_stats - team_names_match_data\n",
        "\n",
        "# Print non-matching names for inspection\n",
        "print(\"Non-matching in Match Data:\", non_matching_names_match_data)\n",
        "print(\"Non-matching in Player Stats:\", non_matching_names_player_stats)\n",
        "\n",
        "english_leagues = ['Premier League', 'Championship', 'FA Cup', 'League One', 'League Two']\n",
        "filtered_df = original_df[original_df['league'].isin(english_leagues)]\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# List all the variables currently in the environment\n",
        "all_vars = globals().copy()\n",
        "all_vars.update(locals())\n",
        "\n",
        "# Filter and print only those variables which are pandas DataFrames\n",
        "for var_name, var_val in all_vars.items():\n",
        "    if isinstance(var_val, pd.DataFrame):\n",
        "        print(f\"{var_name}: {type(var_val)} with shape {var_val.shape}\")\n",
        "\n",
        "# Replace 'df_to_use' with the actual DataFrame you want to filter (e.g., extracted_features_df or combined_player_stats)\n",
        "# Replace 'league_column' with the actual column name that contains league information in your DataFrame\n",
        "\n",
        "df_to_use = extracted_features_df # or combined_player_stats\n",
        "english_leagues = ['Premier League', 'Championship', 'FA Cup', 'EFL League One', 'EFL League Two']\n",
        "filtered_df = df_to_use[df_to_use['league'].isin(english_leagues)]\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(filtered_df.head())\n",
        "\n",
        "\n",
        "\n",
        "# This will display the first few rows of the DataFrame\n",
        "cleaned_matches_data_df.head()\n",
        "\n",
        "# Merge considering 'common_name' as the home team\n",
        "final_dataset_home = pd.merge(\n",
        "    cleaned_matches_data_df,\n",
        "    merged_team_player_stats,\n",
        "    left_on=['home_team_name', 'season'],\n",
        "    right_on=['common_name', 'season'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Merge considering 'common_name' as the away team\n",
        "final_dataset_away = pd.merge(\n",
        "    cleaned_matches_data_df,\n",
        "    merged_team_player_stats,\n",
        "    left_on=['away_team_name', 'season'],\n",
        "    right_on=['common_name', 'season'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# This will display the column names and data types\n",
        "cleaned_matches_data_df.info()\n",
        "\n",
        "# This will display the column names in the DataFrame\n",
        "cleaned_matches_data_df.columns\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# List all variables in the current session\n",
        "# %who\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# List all pandas DataFrames\n",
        "for var in dir():\n",
        "    if isinstance(eval(var), pd.DataFrame):\n",
        "        print(var)\n",
        "\n",
        "print(cleaned_matches_data_df.head())\n",
        "print(cleaned_teams_data.head())\n",
        "print(extracted_features_df.head())\n",
        "print(combined_player_stats.head())\n",
        "print(seasonal_player_stats.head())\n",
        "\n",
        "# Example code to convert data types\n",
        "# cleaned_teams_data['some_column'] = cleaned_teams_data['some_column'].astype(float)\n",
        "# cleaned_matches_data['another_column'] = cleaned_matches_data['another_column'].astype(int)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = extracted_features_df.isnull().sum()\n",
        "print(missing_values)\n",
        "\n",
        "file_paths = [\n",
        "    '/content/spain-la-liga-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/portugal-liga-nos-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/italy-serie-a-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/germany-bundesliga-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/france-ligue-1-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/europe-uefa-europa-league-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/europe-uefa-champions-league-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/england-premier-league-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/england-fa-cup-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/england-efl-league-two-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/england-efl-league-one-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/england-championship-players-2023-to-2024-stats.xlsx',\n",
        "\n",
        "    # Add paths for all your files\n",
        "]\n",
        "\n",
        "!pip install openpyxl\n",
        "import pandas as pd\n",
        "\n",
        "file_paths = [\n",
        "    '/content/spain-la-liga-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/portugal-liga-nos-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/italy-serie-a-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/germany-bundesliga-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/france-ligue-1-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/europe-uefa-europa-league-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/europe-uefa-champions-league-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/england-premier-league-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/england-fa-cup-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/england-efl-league-two-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/england-efl-league-one-players-2023-to-2024-stats.xlsx',\n",
        "    '/content/england-championship-players-2023-to-2024-stats.xlsx',\n",
        "\n",
        "    # Add paths for all your files\n",
        "]\n",
        "\n",
        "dfs = []  # List to store individual DataFrames\n",
        "\n",
        "for file in file_paths:\n",
        "    df = pd.read_excel(file)\n",
        "    dfs.append(df)\n",
        "\n",
        "combined_player_stats = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "print(combined_player_stats.head())\n",
        "\n",
        "# Assuming you have a DataFrame named 'combined_player_stats' containing all the player statistics\n",
        "# If you haven't already loaded the data into a DataFrame, do it before running the following code\n",
        "\n",
        "# List of desired features\n",
        "features = [\n",
        "    \"full_name\", \"age\", \"position\", \"Current Club\", \"league\", \"season\",\n",
        "    \"minutes_played_overall\", \"appearances_overall\", \"yellow_cards_overall\", \"red_cards_overall\",\n",
        "    \"goals_per_90_overall\", \"assists_per_90_overall\", \"xg_per_90_overall\", \"xa_per_90_overall\",\n",
        "    \"npxg_per_90_overall\", \"clean_sheets_overall\", \"tackles_per_90_overall\", \"interceptions_per_90_overall\",\n",
        "    \"distance_travelled_per_90_overall\", \"aerial_duels_won_per_90_overall\", \"goals_overall\",\n",
        "    \"assists_overall\", \"shots_on_target_per_90_overall\", \"shot_conversion_rate_overall\",\n",
        "    \"key_passes_per_90_overall\", \"through_passes_per_90_overall\", \"chances_created_per_90_overall\",\n",
        "    \"dribbles_per_90_overall\", \"dribbles_successful_percentage_overall\", \"passes_per_90_overall\",\n",
        "    \"pass_completion_rate_overall\", \"average_rating_overall\"\n",
        "]\n",
        "\n",
        "# Extracting the features\n",
        "extracted_features_df = combined_player_stats[features]\n",
        "\n",
        "# Displaying the first few rows of the extracted features DataFrame\n",
        "print(extracted_features_df.head())\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = extracted_features_df.isnull().sum()\n",
        "print(missing_values)\n",
        "\n",
        "# Define a threshold for the minimum number of non-missing values required to keep a row\n",
        "threshold = len(extracted_features_df.columns) - 5  # For example, allow up to 5 missing values\n",
        "\n",
        "# Filter out rows with missing values above the threshold\n",
        "extracted_features_df = extracted_features_df.dropna(thresh=threshold)\n",
        "\n",
        "\n",
        "\n",
        "# Check for missing values after filtering\n",
        "print(extracted_features_df.isnull().sum())\n",
        "\n",
        "# Check the size of the DataFrame after filtering\n",
        "print(extracted_features_df.shape)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Save your cleaned DataFrame to a CSV file\n",
        "csv_file_path = '/content/cleaned_player_stats.csv'\n",
        "extracted_features_df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "# Download the file to your local system\n",
        "files.download(csv_file_path)\n",
        "\n",
        "# Assuming 'extracted_features_df' has a 'Current Club' column that matches the team name in your match data\n",
        "\n",
        "# If necessary, standardize team names across datasets\n",
        "extracted_features_df['Current Club'] = extracted_features_df['Current Club'].str.strip().str.lower()\n",
        "match_stats_df['home_team_name'] = match_stats_df['home_team_name'].str.strip().str.lower()\n",
        "match_stats_df['away_team_name'] = match_stats_df['away_team_name'].str.strip().str.lower()\n",
        "\n",
        "!pip install --upgrade pandas openpyxl"
      ],
      "metadata": {
        "id": "BgpSS8pVXxo4"
      },
      "id": "BgpSS8pVXxo4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FibAphCkXwjo"
      },
      "id": "FibAphCkXwjo"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b1HTYMhQXwmx"
      },
      "id": "b1HTYMhQXwmx"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wSPn2UanXwpr"
      },
      "id": "wSPn2UanXwpr"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vbV3WMvSXwsY"
      },
      "id": "vbV3WMvSXwsY"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Eh2eNAKVXwvK"
      },
      "id": "Eh2eNAKVXwvK"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j_cTsu47XwzH"
      },
      "id": "j_cTsu47XwzH"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t68uoyfoXw1z"
      },
      "id": "t68uoyfoXw1z"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pHIWDJb3Xw4e"
      },
      "id": "pHIWDJb3Xw4e"
    },
    {
      "cell_type": "markdown",
      "id": "69318a6e",
      "metadata": {
        "id": "69318a6e"
      },
      "source": [
        "## Automation for Ease of Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4783a25c",
      "metadata": {
        "id": "4783a25c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# AUTOMATION FOR EASE OF PIPELINE\n",
        "# (Insert the pipeline automation code here)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/94_betting_model/'"
      ],
      "metadata": {
        "id": "TfJYthFb-xcU"
      },
      "id": "TfJYthFb-xcU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode"
      ],
      "metadata": {
        "id": "crVopZtp-yNF"
      },
      "id": "crVopZtp-yNF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping specified columns\n",
        "columns_to_drop = ['attendance', 'booked_over05_percentage_overall',\n",
        "                   'booked_over05_percentage_percentile_overall',\n",
        "                   'shirt_number', 'annual_salary_gbp', 'annual_salary_usd']\n",
        "\n",
        "combined_player_stats.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "cleaned_matches_data_df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "\n",
        "# Checking the DataFrame after dropping the columns\n",
        "print(combined_player_stats.head())\n",
        "print(cleaned_matches_data_df.head())"
      ],
      "metadata": {
        "id": "8GIbX4kdAmP_"
      },
      "id": "8GIbX4kdAmP_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the columns of both dataframes\n",
        "print(\"Columns in cleaned_matches_data_df:\", cleaned_matches_data_df.columns)\n",
        "print(\"Columns in combined_player_stats:\", combined_player_stats.columns)"
      ],
      "metadata": {
        "id": "TZRu0lZwAmgv"
      },
      "id": "TZRu0lZwAmgv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns in cleaned_matches_data_df:\", cleaned_matches_data_df.columns.tolist())\n",
        "print(\"Columns in combined_player_stats:\", combined_player_stats.columns.tolist())\n"
      ],
      "metadata": {
        "id": "hePcqOWQA5M3"
      },
      "id": "hePcqOWQA5M3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'Current Club' and 'league' are the columns in players dataframe\n",
        "team_league_mapping = combined_player_stats[['Current Club', 'league']].drop_duplicates()\n",
        "team_league_mapping = team_league_mapping.set_index('Current Club')['league'].to_dict()\n"
      ],
      "metadata": {
        "id": "ukCK9oMRA8rR"
      },
      "id": "ukCK9oMRA8rR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get league from team name\n",
        "def get_league(team_name):\n",
        "    return team_league_mapping.get(team_name, \"Unknown\")\n",
        "\n",
        "# Apply the function to the matches dataframe\n",
        "cleaned_matches_data_df['league'] = cleaned_matches_data_df['home_team_name'].apply(get_league)\n"
      ],
      "metadata": {
        "id": "MaQgdmP2BCai"
      },
      "id": "MaQgdmP2BCai",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for matches with 'Unknown' league\n",
        "unknown_league_matches = cleaned_matches_data_df[cleaned_matches_data_df['league'] == \"Unknown\"]\n",
        "print(unknown_league_matches)\n"
      ],
      "metadata": {
        "id": "kNqrXGu4BDsg"
      },
      "id": "kNqrXGu4BDsg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jpj9ouGqBGSc"
      },
      "id": "jpj9ouGqBGSc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement the Full-Time Result (FTR) calculation along with other necessary statistics, you can use the following steps:\n",
        "\n",
        "Calculate Team Form: This function calculates the form of each team over the last 'n' matches.\n",
        "\n",
        "Calculate Head-to-Head Statistics: This function calculates head-to-head statistics between two teams.\n",
        "\n",
        "Create FTR Column: This function adds a new column to your DataFrame that indicates the full-time result of each match.\n",
        "\n",
        "Here's the code for these steps:"
      ],
      "metadata": {
        "id": "vcAr5cwd-5Qv"
      },
      "id": "vcAr5cwd-5Qv"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bi5EBNaI-6L2"
      },
      "id": "Bi5EBNaI-6L2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to calculate form for a given number of matches"
      ],
      "metadata": {
        "id": "tApoSYQv-96h"
      },
      "id": "tApoSYQv-96h"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to calculate form for a given number of matches\n",
        "def calculate_form(df, team_name, n_matches=5):\n",
        "    recent_matches = df[(df['home_team_name'] == team_name) | (df['away_team_name'] == team_name)]\n",
        "    recent_matches = recent_matches.sort_values('date_GMT').tail(n_matches)\n",
        "    points = 0\n",
        "    for index, row in recent_matches.iterrows():\n",
        "        if row['home_team_name'] == team_name:\n",
        "            if row['home_team_goal_count'] > row['away_team_goal_count']:\n",
        "                points += 3  # Home win\n",
        "            elif row['home_team_goal_count'] == row['away_team_goal_count']:\n",
        "                points += 1  # Draw\n",
        "        else:  # Away team\n",
        "            if row['away_team_goal_count'] > row['home_team_goal_count']:\n",
        "                points += 3  # Away win\n",
        "            elif row['away_team_goal_count'] == row['home_team_goal_count']:\n",
        "                points += 1  # Draw\n",
        "    return points / (3 * n_matches)  # Average points per match\n",
        "\n",
        "# Function to calculate head-to-head statistics\n",
        "def calculate_head_to_head_stats(df, team1, team2):\n",
        "    matches = df[((df['home_team_name'] == team1) & (df['away_team_name'] == team2)) |\n",
        "                 ((df['home_team_name'] == team2) & (df['away_team_name'] == team1))]\n",
        "    home_wins = len(matches[(matches['home_team_name'] == team1) & (matches['home_team_goal_count'] > matches['away_team_goal_count'])])\n",
        "    away_wins = len(matches[(matches['home_team_name'] == team2) & (matches['home_team_goal_count'] < matches['away_team_goal_count'])])\n",
        "    draws = len(matches[matches['home_team_goal_count'] == matches['away_team_goal_count']])\n",
        "    return {'home_wins': home_wins, 'away_wins': away_wins, 'draws': draws}\n",
        "\n",
        "# Function to create FTR column\n",
        "def create_ftr_column(df):\n",
        "    df['FTR'] = df.apply(lambda row: 0 if row['home_team_goal_count'] > row['away_team_goal_count'] else 1, axis=1)\n",
        "\n",
        "# Apply these functions to your DataFrame\n",
        "# Assuming 'combined_leagues_df' is your main DataFrame\n",
        "combined_leagues_df['home_team_form'] = combined_leagues_df.apply(lambda row: calculate_form(combined_leagues_df, row['home_team_name']), axis=1)\n",
        "combined_leagues_df['away_team_form'] = combined_leagues_df.apply(lambda row: calculate_form(combined_leagues_df, row['away_team_name']), axis=1)\n",
        "combined_leagues_df['head_to_head'] = combined_leagues_df.apply(lambda row: calculate_head_to_head_stats(combined_leagues_df, row['home_team_name'], row['away_team_name']), axis=1)\n",
        "create_ftr_column(combined_leagues_df)\n",
        "\n",
        "# Now your DataFrame will have new columns for team form, head-to-head stats, and FTR\n"
      ],
      "metadata": {
        "id": "1kY1PsXN--hR"
      },
      "id": "1kY1PsXN--hR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7TxTTL02_CZs"
      },
      "id": "7TxTTL02_CZs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THIS IS USEFUL FOR TEAM AND PLAYER AGGREGATION\n",
        "\n",
        "Results Visualization Visualize the results of the model.\n",
        "\n",
        "Double-click (or enter) to edit"
      ],
      "metadata": {
        "id": "DJ4vxl68BLhP"
      },
      "id": "DJ4vxl68BLhP"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example: Aggregating player stats for a team in a particular match\n",
        "# Let's say you have a function that takes a team name and a date and returns the aggregated stats for that team\n",
        "def get_team_stats_for_match(team_name, match_date, player_stats_df):\n",
        "    # Filter player stats for the given team and date\n",
        "    # Aggregate stats as needed (e.g., average rating, total goals)\n",
        "    # Return aggregated stats as a pandas Series or DataFrame row\n",
        "    pass\n",
        "\n",
        "# Loop through each match in the match data\n",
        "for index, row in cleaned_matches_data_df.iterrows():\n",
        "    # Get team names and match date\n",
        "    home_team = row['home_team_name']\n",
        "    away_team = row['away_team_name']\n",
        "    match_date = row['date_GMT']\n",
        "\n",
        "    # Get aggregated stats for both teams\n",
        "    home_team_stats = get_team_stats_for_match(home_team, match_date, combined_player_stats)\n",
        "    away_team_stats = get_team_stats_for_match(away_team, match_date, combined_player_stats)\n",
        "\n",
        "    # Merge these stats into the match data row\n",
        "    # This can be done by setting new columns in 'row' or by merging Series/DataFrames\n",
        "\n",
        "# Now 'cleaned_matches_data_df' will have additional columns for each team's player stats"
      ],
      "metadata": {
        "id": "fUrJGSUrBMJ1"
      },
      "id": "fUrJGSUrBMJ1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate form\n",
        "def calculate_form(df, num_matches):\n",
        "    form = []\n",
        "    for team in df['home_team_name'].unique():\n",
        "        team_matches = df[(df['home_team_name'] == team) | (df['away_team_name'] == team)]\n",
        "        team_matches = team_matches.sort_values('date_GMT').tail(num_matches)\n",
        "        team_form = 0\n",
        "        for index, row in team_matches.iterrows():\n",
        "            if row['home_team_name'] == team:\n",
        "                if row['home_team_goal_count'] > row['away_team_goal_count']:\n",
        "                    team_form += 3  # Win\n",
        "                elif row['home_team_goal_count'] == row['away_team_goal_count']:\n",
        "                    team_form += 1  # Draw\n",
        "            elif row['away_team_name'] == team:\n",
        "                if row['away_team_goal_count'] > row['home_team_goal_count']:\n",
        "                    team_form += 3  # Win\n",
        "                elif row['away_team_goal_count'] == row['home_team_goal_count']:\n",
        "                    team_form += 1  # Draw\n",
        "        form.append({'team': team, 'form': team_form})\n",
        "    return pd.DataFrame(form)\n",
        "\n",
        "# Calculate form for teams\n",
        "team_form_df = calculate_form(cleaned_matches_data_df, 5)\n"
      ],
      "metadata": {
        "id": "I0qaMlbMBRn4"
      },
      "id": "I0qaMlbMBRn4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate form\n",
        "def calculate_form(df, num_matches):\n",
        "    form = []\n",
        "    for team in df['away_team_name'].unique():\n",
        "        team_matches = df[(df['home_team_name'] == team) | (df['away_team_name'] == team)]\n",
        "        team_matches = team_matches.sort_values('date_GMT').tail(num_matches)\n",
        "        team_form = 0\n",
        "        for index, row in team_matches.iterrows():\n",
        "            if row['home_team_name'] == team:\n",
        "                if row['home_team_goal_count'] > row['away_team_goal_count']:\n",
        "                    team_form += 3  # Win\n",
        "                elif row['home_team_goal_count'] == row['away_team_goal_count']:\n",
        "                    team_form += 1  # Draw\n",
        "            elif row['away_team_name'] == team:\n",
        "                if row['away_team_goal_count'] > row['home_team_goal_count']:\n",
        "                    team_form += 3  # Win\n",
        "                elif row['away_team_goal_count'] == row['home_team_goal_count']:\n",
        "                    team_form += 1  # Draw\n",
        "        form.append({'team': team, 'form': team_form})\n",
        "    return pd.DataFrame(form)\n",
        "\n",
        "# Calculate form for teams\n",
        "team_form_df = calculate_form(cleaned_matches_data_df, 5)"
      ],
      "metadata": {
        "id": "CpphTon7BVH9"
      },
      "id": "CpphTon7BVH9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def head_to_head_stats(df, team1, team2):\n",
        "    matches = df[((df['home_team_name'] == team1) & (df['away_team_name'] == team2)) |\n",
        "                 ((df['home_team_name'] == team2) & (df['away_team_name'] == team1))]\n",
        "    # Perform calculations to find head-to-head stats\n",
        "    # ...\n",
        "\n",
        "# Example usage\n",
        "head_to_head_stats(cleaned_matches_data_df, 'Team A', 'Team B')"
      ],
      "metadata": {
        "id": "235GIdBBBXpt"
      },
      "id": "235GIdBBBXpt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "team_form_df['form_average'] = team_form_df['form'] / 5  # Assuming 5 is the number of matches considered for form"
      ],
      "metadata": {
        "id": "SRBwdEj9BaJ2"
      },
      "id": "SRBwdEj9BaJ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ftr_column(df):\n",
        "    df['FTR'] = df.apply(lambda row: 0 if row['home_team_goal_count'] > row['away_team_goal_count'] else 1, axis=1)\n",
        "\n",
        "create_ftr_column(cleaned_matches_data_df)\n"
      ],
      "metadata": {
        "id": "tA30ZlXsBaoL"
      },
      "id": "tA30ZlXsBaoL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame\n",
        "print(cleaned_matches_data_df.head())"
      ],
      "metadata": {
        "id": "7esDHkVmBasH"
      },
      "id": "7esDHkVmBasH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Replace 'Team A' and 'Team B' with actual team names\n",
        "sample_teams = cleaned_matches_data_df[(cleaned_matches_data_df['home_team_name'] == 'Manchester City') |\n",
        "                                       (cleaned_matches_data_df['away_team_name'] == 'Liverpool')]\n",
        "print(sample_teams[['home_team_name', 'away_team_name', 'FTR',]])\n"
      ],
      "metadata": {
        "id": "LSYNzwu8BiDe"
      },
      "id": "LSYNzwu8BiDe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all column names\n",
        "print(cleaned_matches_data_df.columns)\n"
      ],
      "metadata": {
        "id": "a6hdXXeuBiGR"
      },
      "id": "a6hdXXeuBiGR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if 'form' column exists\n",
        "if 'form' in cleaned_matches_data_df.columns:\n",
        "    print(\"Column 'form' exists in the DataFrame.\")\n",
        "else:\n",
        "    print(\"Column 'form' does not exist in the DataFrame.\")\n"
      ],
      "metadata": {
        "id": "3d3UlsM9BiJb"
      },
      "id": "3d3UlsM9BiJb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_form(df, team_name, n_matches=5):\n",
        "    \"\"\"\n",
        "    Calculate the form of a team over the last n matches.\n",
        "    \"\"\"\n",
        "    recent_matches = df[df['home_team_name'] == team_name].tail(n_matches)\n",
        "    points = 0\n",
        "    for index, row in recent_matches.iterrows():\n",
        "        if row['home_team_goal_count'] > row['away_team_goal_count']:\n",
        "            points += 3  # Home win\n",
        "        elif row['home_team_goal_count'] == row['away_team_goal_count']:\n",
        "            points += 1  # Draw\n",
        "    return points / (3 * n_matches)  # Return the average points per match"
      ],
      "metadata": {
        "id": "HZ-V5CZIBavL"
      },
      "id": "HZ-V5CZIBavL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate form for each team and each match\n",
        "cleaned_matches_data_df['home_team_form'] = cleaned_matches_data_df.apply(\n",
        "    lambda row: calculate_form(cleaned_matches_data_df, row['home_team_name']), axis=1)\n",
        "\n",
        "cleaned_matches_data_df['away_team_form'] = cleaned_matches_data_df.apply(\n",
        "    lambda row: calculate_form(cleaned_matches_data_df, row['away_team_name']), axis=1)\n"
      ],
      "metadata": {
        "id": "_XleHluWBoEp"
      },
      "id": "_XleHluWBoEp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_head_to_head_stats(df, home_team, away_team):\n",
        "    \"\"\"\n",
        "    Calculate head-to-head statistics between two teams.\n",
        "    \"\"\"\n",
        "    # Filter matches where either team was playing at home against the other\n",
        "    head_to_head_matches = df[((df['home_team_name'] == home_team) & (df['away_team_name'] == away_team)) |\n",
        "                              ((df['home_team_name'] == away_team) & (df['away_team_name'] == home_team))]\n",
        "\n",
        "    # Calculate stats like number of wins, draws, losses, goals scored, etc.\n",
        "    home_wins = len(head_to_head_matches[(head_to_head_matches['home_team_name'] == home_team) &\n",
        "                                         (head_to_head_matches['home_team_goal_count'] > head_to_head_matches['away_team_goal_count'])])\n",
        "    away_wins = len(head_to_head_matches[(head_to_head_matches['home_team_name'] == away_team) &\n",
        "                                         (head_to_head_matches['home_team_goal_count'] < head_to_head_matches['away_team_goal_count'])])\n",
        "    draws = len(head_to_head_matches[head_to_head_matches['home_team_goal_count'] == head_to_head_matches['away_team_goal_count']])\n",
        "\n",
        "    # Return a dictionary of stats\n",
        "    return {\n",
        "        'home_wins': home_wins,\n",
        "        'away_wins': away_wins,\n",
        "        'draws': draws\n",
        "    }\n",
        "\n",
        "# Apply the function to each match\n",
        "cleaned_matches_data_df['head_to_head'] = cleaned_matches_data_df.apply(\n",
        "    lambda row: calculate_head_to_head_stats(cleaned_matches_data_df, row['home_team_name'], row['away_team_name']), axis=1)"
      ],
      "metadata": {
        "id": "uJ3AZwgNBoHs"
      },
      "id": "uJ3AZwgNBoHs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_ftr(home_goals, away_goals):\n",
        "    if home_goals > away_goals:\n",
        "        return 0  # Home win\n",
        "    else:\n",
        "        return 1  # Draw or Away win\n",
        "\n",
        "cleaned_matches_data_df['FTR'] = cleaned_matches_data_df.apply(\n",
        "    lambda row: calculate_ftr(row['home_team_goal_count'], row['away_team_goal_count']), axis=1)\n"
      ],
      "metadata": {
        "id": "6C9clOxLB0qh"
      },
      "id": "6C9clOxLB0qh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, save your DataFrame to a CSV file\n",
        "cleaned_matches_data_df.to_csv('/content/cleaned_matches_data_with_features.csv', index=False)\n"
      ],
      "metadata": {
        "id": "3esYpcBTB3W-"
      },
      "id": "3esYpcBTB3W-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming you have already loaded cleaned_matches_data_df\n",
        "print(cleaned_matches_data_df.describe())\n",
        "\n",
        "# Histograms for continuous variables in matches data\n",
        "cleaned_matches_data_df[['home_team_goal_count', 'away_team_goal_count']].hist(bins=15, figsize=(15, 6))\n",
        "\n",
        "# Scatter Plot for relationships in matches data\n",
        "plt.scatter(cleaned_matches_data_df['home_team_shots'], cleaned_matches_data_df['home_team_goal_count'])\n",
        "plt.xlabel('Home Team Shots')\n",
        "plt.ylabel('Home Team Goals')\n",
        "plt.title('Home Team Shots vs Goals')\n",
        "\n",
        "# Correlation Heatmap for matches data\n",
        "corr_matches = cleaned_matches_data_df.corr()\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(corr_matches, annot=True, fmt=\".2f\")\n"
      ],
      "metadata": {
        "id": "ZoeSAkecBoK2"
      },
      "id": "ZoeSAkecBoK2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already loaded combined_player_stats\n",
        "print(combined_player_stats.describe())\n",
        "\n",
        "# Histograms for continuous variables in player stats\n",
        "combined_player_stats[['age', 'minutes_played_overall', 'goals_per_90_overall']].hist(bins=15, figsize=(15, 6))\n",
        "\n",
        "# Scatter Plot for relationships in player stats\n",
        "plt.scatter(combined_player_stats['goals_overall'], combined_player_stats['assists_overall'])\n",
        "plt.xlabel('Goals')\n",
        "plt.ylabel('Assists')\n",
        "plt.title('Goals vs Assists in Player Stats')\n",
        "\n",
        "# Correlation Heatmap for player stats\n",
        "corr_players = combined_player_stats.corr()\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(corr_players, annot=True, fmt=\".2f\")"
      ],
      "metadata": {
        "id": "E3QUSapACG__"
      },
      "id": "E3QUSapACG__",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_matches_data_df['FTR'] = (cleaned_matches_data_df['home_team_goal_count'] <= cleaned_matches_data_df['away_team_goal_count']).astype(int)\n"
      ],
      "metadata": {
        "id": "KtjldoeCCH1U"
      },
      "id": "KtjldoeCCH1U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'combined_player_stats' is your DataFrame with player stats\n",
        "shot_related_columns = [col for col in combined_player_stats.columns if 'shot' in col.lower()]\n",
        "print(shot_related_columns)"
      ],
      "metadata": {
        "id": "330eEwXUCH4S"
      },
      "id": "330eEwXUCH4S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling division by zero\n",
        "combined_player_stats['shot_efficiency'] = combined_player_stats.apply(\n",
        "    lambda row: row['goals_overall'] / row['shots_total_overall'] if row['shots_total_overall'] > 0 else 0, axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "qNDjWiIfCPpC"
      },
      "id": "qNDjWiIfCPpC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shot Efficiency\n",
        "combined_player_stats['shot_efficiency'] = combined_player_stats['goals_overall'] / combined_player_stats['shots_total_overall']\n",
        "\n",
        "# Shots on Target Rate\n",
        "combined_player_stats['shots_on_target_rate'] = combined_player_stats['shots_on_target_total_overall'] / combined_player_stats['shots_total_overall']\n",
        "\n",
        "# Conversion Rate\n",
        "combined_player_stats['conversion_rate'] = combined_player_stats['goals_overall'] / combined_player_stats['shots_on_target_total_overall']\n",
        "\n",
        "# Shooting Accuracy\n",
        "combined_player_stats['shooting_accuracy'] = combined_player_stats['shots_on_target_total_overall'] / combined_player_stats['shots_total_overall']\n",
        "\n",
        "# Defensive Pressure\n",
        "combined_player_stats['defensive_pressure'] = combined_player_stats['shots_faced_total_overall'] / combined_player_stats['appearances_overall']\n",
        "\n",
        "# Goalkeeping Performance\n",
        "# Assuming 'goals_conceded_overall' is the number of goals a goalkeeper has conceded\n",
        "combined_player_stats['goalkeeper_performance'] = combined_player_stats['conceded_per_90_overall'] / combined_player_stats['shots_faced_total_overall']\n",
        "\n",
        "# Long-Shot Specialist\n",
        "combined_player_stats['long_shot_specialist'] = combined_player_stats['shots_total_overall'] - combined_player_stats['shots_on_target_total_overall']\n",
        "\n",
        "# Shot Conversion Rate Standardized\n",
        "shot_conversion_mean = combined_player_stats['shot_conversion_rate_overall'].mean()\n",
        "shot_conversion_std = combined_player_stats['shot_conversion_rate_overall'].std()\n",
        "combined_player_stats['shot_conversion_rate_standardized'] = (combined_player_stats['shot_conversion_rate_overall'] - shot_conversion_mean) / shot_conversion_std\n",
        "\n",
        "# Before running this code, ensure that there are no divisions by zero and handle any NaN values that may result from these computations.\n"
      ],
      "metadata": {
        "id": "yZIRamJcCH6y"
      },
      "id": "yZIRamJcCH6y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_player_stats.columns)\n"
      ],
      "metadata": {
        "id": "L2-w9XKTCTdN"
      },
      "id": "L2-w9XKTCTdN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_team_goal_count', 'away_team_goal_count', 'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match', 'odds_ft_home_team_win', 'odds_ft_draw', 'odds_ft_away_team_win']\n"
      ],
      "metadata": {
        "id": "pmEbNFy9B6gP"
      },
      "id": "pmEbNFy9B6gP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting features - example features selected here\n",
        "features = df[['Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_ppg', 'away_ppg',\n",
        "               'Home Team Pre-Match xG', 'Away Team Pre-Match xG',\n",
        "               'average_goals_per_match_pre_match', 'btts_percentage_pre_match',\n",
        "               'over_15_percentage_pre_match', 'over_25_percentage_pre_match',\n",
        "               'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match',\n",
        "               'odds_ft_home_team_win', 'odds_ft_draw', 'odds_ft_away_team_win',\n",
        "               'league', 'home_team_form', 'away_team_form', 'head_to_head']]\n",
        "\n",
        "# Target variable\n",
        "target = df['FTR']\n",
        "\n",
        "# Checking the selected features and target\n",
        "print(\"Selected Features Sample:\")\n",
        "print(features.head())\n",
        "\n",
        "print(\"\\nTarget Variable Sample:\")\n",
        "print(target.head())"
      ],
      "metadata": {
        "id": "AQoeniD2CYv1"
      },
      "id": "AQoeniD2CYv1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pX_RwGEqCbik"
      },
      "id": "pX_RwGEqCbik",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qFhOhPfHCbls"
      },
      "id": "qFhOhPfHCbls",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yB6IupvFCboq"
      },
      "id": "yB6IupvFCboq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K8kNrTN8CbxY"
      },
      "id": "K8kNrTN8CbxY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b524c1fa",
      "metadata": {
        "id": "b524c1fa"
      },
      "source": [
        "## Sentiment Analysis Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a63680a",
      "metadata": {
        "id": "2a63680a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Sentiment Analysis Integration\n",
        "# (Code for sentiment analysis will be added here)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "140f1759",
      "metadata": {
        "id": "140f1759"
      },
      "source": [
        "## Model Training and Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0599e867",
      "metadata": {
        "id": "0599e867"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Model Training and Prediction\n",
        "# (Code for model training and prediction will be added here)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "this runs for predictions\n",
        "\n",
        "Feature Engineering Create and modify features for the model."
      ],
      "metadata": {
        "id": "SVRSyrkv_H6K"
      },
      "id": "SVRSyrkv_H6K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load the model from the file\n",
        "model_path = '/content/drive/My Drive/94_betting_model/94_betting_model.pkl'  # Update with your correct path\n",
        "model = joblib.load(model_path)\n",
        "\n",
        "# Assuming 'combined_leagues_df' is your new data\n",
        "# And 'selected_features' are the features used by the model\n",
        "selected_features = ['Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_team_goal_count', 'away_team_goal_count', 'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match', 'odds_ft_home_team_win', 'odds_ft_draw', 'odds_ft_away_team_win']\n",
        "\n",
        "# Select the features from your new data\n",
        "X_new = combined_leagues_df[selected_features]\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "# Add predictions to the DataFrame\n",
        "combined_leagues_df['Predicted_FTR'] = predictions\n",
        "\n",
        "# Optionally, you can save the DataFrame with predictions to a new CSV file\n",
        "combined_leagues_df.to_csv('/content/drive/My Drive/94_betting_model/predictions.csv', index=False)\n"
      ],
      "metadata": {
        "id": "lO6c2M6e_IJq"
      },
      "id": "lO6c2M6e_IJq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for missing values\n",
        "print(\"Missing values in matches data:\")\n",
        "print(cleaned_matches_data_df.isnull().sum())\n",
        "\n",
        "print(\"\\nMissing values in player stats data:\")\n",
        "print(combined_player_stats.isnull().sum())\n",
        "\n",
        "# Handling missing values - Example: fill with a default value or drop\n",
        "# cleaned_matches_data_df.fillna(0, inplace=True)\n",
        "# combined_player_stats.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "vQNqcgDQAbzr"
      },
      "id": "vQNqcgDQAbzr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your predictions DataFrame\n",
        "# Replace 'your_predictions_file_path' with the path to your CSV file containing predictions\n",
        "predictions_df = pd.read_csv('/content/drive/My Drive/94_betting_model/predictions.csv')\n",
        "\n",
        "# Analyze Prediction Patterns\n",
        "home_wins = predictions_df[predictions_df['FTR'] == 0].shape[0]  # Assuming 0 represents home wins\n",
        "draws = predictions_df[predictions_df['FTR'] == 1].shape[0]      # Assuming 1 represents draws\n",
        "away_wins = predictions_df[predictions_df['FTR'] == 2].shape[0]  # Assuming 2 represents away wins\n",
        "\n",
        "print(f\"Home Wins: {home_wins}, Draws: {draws}, Away Wins: {away_wins}\")\n",
        "\n",
        "# Exporting Data for Records\n",
        "predictions_df.to_csv('your_predictions.csv', index=False)\n",
        "\n",
        "# Note: Since actual outcomes are not available, accuracy cannot be computed at this stage."
      ],
      "metadata": {
        "id": "r4XntP4n_IQn"
      },
      "id": "r4XntP4n_IQn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of specific dates and times\n",
        "dates_and_times_of_interest = [\n",
        "    'Nov 30 2023 - 5:45pm', 'Nov 30 2023 - 8:00pm', 'Nov 29 2023 - 8:00pm',\n",
        "    'Dec 02 2023 - 3:00pm', 'Dec 05 2023 - 7:30pm', 'Dec 02 2023 - 5:30pm',\n",
        "    'Dec 03 2023 - 2:00pm', 'Dec 02 2023 - 8:00pm', 'Dec 03 2023 - 4:30pm',\n",
        "    'Dec 06 2023 - 7:30pm'\n",
        "]\n",
        "\n",
        "# Convert string dates to datetime format\n",
        "dates_and_times_of_interest = pd.to_datetime(dates_and_times_of_interest, format='%b %d %Y - %I:%M%p')\n",
        "\n",
        "# Filter the DataFrame for the specified dates and times\n",
        "matches_on_dates = combined_leagues_df[combined_leagues_df['date_GMT'].isin(dates_and_times_of_interest)]\n",
        "\n",
        "print(f\"Number of matches on specified dates and times: {len(matches_on_dates)}\")\n",
        "\n",
        "# Check if the required feature columns are present\n",
        "print(\"Checking if the required feature columns are present:\")\n",
        "for col in feature_columns:\n",
        "    if col not in combined_leagues_df.columns:\n",
        "        print(f\"Missing column: {col}\")\n",
        "\n",
        "# Display first few rows for the dates of interest\n",
        "matches_on_dates.head()"
      ],
      "metadata": {
        "id": "JmUCQmlX_V1x"
      },
      "id": "JmUCQmlX_V1x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the filtered DataFrame\n",
        "print(matches_on_dates)\n",
        "\n",
        "# Save the filtered DataFrame to a CSV file\n",
        "csv_filename = '/content/drive/My Drive/94_betting_model/matches_on_specific_dates.csv'\n",
        "matches_on_dates.to_csv(csv_filename, index=False)\n",
        "\n",
        "print(f\"Filtered matches saved to {csv_filename}\")\n"
      ],
      "metadata": {
        "id": "fw4eFWFT_czu"
      },
      "id": "fw4eFWFT_czu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the DataFrame contains the required dates\n",
        "print(\"Dates in the dataset:\", combined_leagues_df['date_GMT'].unique())\n",
        "\n",
        "# Check if the feature columns are available in the DataFrame\n",
        "print(\"Columns in the DataFrame:\", combined_leagues_df.columns)"
      ],
      "metadata": {
        "id": "PvV96-Ue_hW0"
      },
      "id": "PvV96-Ue_hW0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if X is empty\n",
        "if X.empty:\n",
        "    print(\"The feature DataFrame 'X' is empty.\")\n",
        "else:\n",
        "    # Print the shape and column names of X\n",
        "    print(\"Shape of X:\", X.shape)\n",
        "    print(\"Columns in X:\", X.columns.tolist())\n",
        "\n",
        "    # Optionally, check the first few rows of X to verify data\n",
        "    print(X.head())"
      ],
      "metadata": {
        "id": "_CaBd1Qi_k7b"
      },
      "id": "_CaBd1Qi_k7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "843622ab",
      "metadata": {
        "id": "843622ab"
      },
      "source": [
        "## Generating Prediction Reports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bda070f5",
      "metadata": {
        "id": "bda070f5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Generating Prediction Reports\n",
        "# (Code for generating prediction reports will be added here)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n"
      ],
      "metadata": {
        "id": "yGVSuR1F_2_8"
      },
      "id": "yGVSuR1F_2_8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load the model from the file\n",
        "model_path = '/content/drive/My Drive/94_betting_model/94_betting_model.pkl'  # Update with your correct path\n",
        "model = joblib.load(model_path)\n",
        "\n",
        "# Assuming 'combined_leagues_df' is your new data\n",
        "# And 'selected_features' are the features used by the model\n",
        "selected_features = ['Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_team_goal_count', 'away_team_goal_count', 'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match', 'odds_ft_home_team_win', 'odds_ft_draw', 'odds_ft_away_team_win']\n",
        "\n",
        "# Select the features from your new data\n",
        "X_new = combined_leagues_df[selected_features]\n",
        "\n",
        "# Check if X_new is empty\n",
        "if X_new.empty:\n",
        "    print(\"The feature DataFrame is empty. Check your data selection process.\")\n",
        "else:\n",
        "    # Make predictions\n",
        "    predictions = model.predict(X_new)\n",
        "\n",
        "    # Add predictions to the DataFrame\n",
        "    combined_leagues_df['Predicted_FTR'] = predictions\n",
        "\n",
        "    # Optionally, save the DataFrame with predictions to a new CSV file\n",
        "    combined_leagues_df.to_csv('/content/drive/My Drive/94_betting_model/predictions3.csv', index=False)\n",
        "\n",
        "    print(\"Predictions made and saved successfully.\")\n"
      ],
      "metadata": {
        "id": "I6hLvL38_r_A"
      },
      "id": "I6hLvL38_r_A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'predictions_df' is your DataFrame with predictions and other relevant columns\n",
        "predictions_df.to_csv('/content/drive/My Drive/94_betting_model/predictions_2.csv', index=False)"
      ],
      "metadata": {
        "id": "NSJEKgd9_ZrA"
      },
      "id": "NSJEKgd9_ZrA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'date_GMT' to datetime\n",
        "combined_leagues_df['date_GMT'] = pd.to_datetime(combined_leagues_df['date_GMT'])\n",
        "\n",
        "# Check the range of dates in the dataset\n",
        "print(\"Earliest date in the dataset:\", combined_leagues_df['date_GMT'].min())\n",
        "print(\"Latest date in the dataset:\", combined_leagues_df['date_GMT'].max())\n",
        "\n",
        "# Filter for November 30, 2023\n",
        "nov_30_predictions = combined_leagues_df[combined_leagues_df['date_GMT'] == pd.Timestamp('2023-11-30')]\n",
        "\n",
        "# Check if there are any matches on this date\n",
        "if nov_30_predictions.empty:\n",
        "    print(\"No matches found for November 30, 2023.\")\n",
        "else:\n",
        "    # Extract features and make predictions\n",
        "    X_nov_30 = nov_30_predictions[feature_columns]\n",
        "    nov_30_predictions['predicted_result'] = model.predict(X_nov_30)\n",
        "    nov_30_predictions['predicted_probability'] = model.predict_proba(X_nov_30)[:,1]\n",
        "\n",
        "    # Display the predictions\n",
        "    print(nov_30_predictions[['date_GMT', 'home_team_name', 'away_team_name', 'predicted_result', 'predicted_probability']])\n"
      ],
      "metadata": {
        "id": "26COBp9J_6uZ"
      },
      "id": "26COBp9J_6uZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADJUST DATE HERE TO SET PREDICTION REPORT DATA TO BE IN THE FUTURE FROM THE PRESENT DAY OR PREDICTION RUNNING"
      ],
      "metadata": {
        "id": "TkqDOk-n__AE"
      },
      "id": "TkqDOk-n__AE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for November 28 and 29, 2023\n",
        "nov_28_predictions = combined_leagues_df[combined_leagues_df['date_GMT'] == pd.Timestamp('2023-11-28')]\n",
        "nov_29_predictions = combined_leagues_df[combined_leagues_df['date_GMT'] == pd.Timestamp('2023-11-29')]\n",
        "\n",
        "# Check if there are any matches on these dates\n",
        "if nov_28_predictions.empty and nov_29_predictions.empty:\n",
        "    print(\"No matches found for November 28 and 29, 2023.\")\n",
        "else:\n",
        "    # If there are matches on November 28\n",
        "    if not nov_28_predictions.empty:\n",
        "        X_nov_28 = nov_28_predictions[feature_columns]\n",
        "        nov_28_predictions['predicted_result'] = model.predict(X_nov_28)\n",
        "        nov_28_predictions['predicted_probability'] = model.predict_proba(X_nov_28)[:,1]\n",
        "        print(\"Predictions for November 28, 2023:\")\n",
        "        print(nov_28_predictions[['date_GMT', 'home_team_name', 'away_team_name', 'predicted_result', 'predicted_probability']])\n",
        "\n",
        "    # If there are matches on November 29\n",
        "    if not nov_29_predictions.empty:\n",
        "        X_nov_29 = nov_29_predictions[feature_columns]\n",
        "        nov_29_predictions['predicted_result'] = model.predict(X_nov_29)\n",
        "        nov_29_predictions['predicted_probability'] = model.predict_proba(X_nov_29)[:,1]\n",
        "        print(\"Predictions for November 29, 2023:\")\n",
        "        print(nov_29_predictions[['date_GMT', 'home_team_name', 'away_team_name', 'predicted_result', 'predicted_probability']])\n"
      ],
      "metadata": {
        "id": "GML9cTGu_9-z"
      },
      "id": "GML9cTGu_9-z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for November 30, 2023, at specific times\n",
        "nov_30_545pm_predictions = combined_leagues_df[combined_leagues_df['date_GMT'] == pd.Timestamp('2023-11-30 17:45:00')]\n",
        "nov_30_800pm_predictions = combined_leagues_df[combined_leagues_df['date_GMT'] == pd.Timestamp('2023-11-30 20:00:00')]\n",
        "\n",
        "# Check if there are any matches at these times\n",
        "if nov_30_545pm_predictions.empty and nov_30_800pm_predictions.empty:\n",
        "    print(\"No matches found for November 30, 2023, at 5:45 pm and 8:00 pm.\")\n",
        "else:\n",
        "    # If there are matches at 5:45 pm\n",
        "    if not nov_30_545pm_predictions.empty:\n",
        "        X_nov_30_545pm = nov_30_545pm_predictions[feature_columns]\n",
        "        nov_30_545pm_predictions['predicted_result'] = model.predict(X_nov_30_545pm)\n",
        "        nov_30_545pm_predictions['predicted_probability'] = model.predict_proba(X_nov_30_545pm)[:,1]\n",
        "        print(\"Predictions for November 30, 2023, at 5:45 pm:\")\n",
        "        print(nov_30_545pm_predictions[['date_GMT', 'home_team_name', 'away_team_name', 'predicted_result', 'predicted_probability']])\n",
        "\n",
        "    # If there are matches at 8:00 pm\n",
        "    if not nov_30_800pm_predictions.empty:\n",
        "        X_nov_30_800pm = nov_30_800pm_predictions[feature_columns]\n",
        "        nov_30_800pm_predictions['predicted_result'] = model.predict(X_nov_30_800pm)\n",
        "        nov_30_800pm_predictions['predicted_probability'] = model.predict_proba(X_nov_30_800pm)[:,1]\n",
        "        print(\"Predictions for November 30, 2023, at 8:00 pm:\")\n",
        "        print(nov_30_800pm_predictions[['date_GMT', 'home_team_name', 'away_team_name', 'predicted_result', 'predicted_probability']])\n"
      ],
      "metadata": {
        "id": "qMiNYICaAHZi"
      },
      "id": "qMiNYICaAHZi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_ftr(home_goals, away_goals):\n",
        "    \"\"\"\n",
        "    Calculate the Full Time Result (FTR).\n",
        "    Home win (0), draw (1), away win (2).\n",
        "    \"\"\"\n",
        "    if home_goals > away_goals:\n",
        "        return 0  # Home win\n",
        "    elif home_goals == away_goals:\n",
        "        return 1  # Draw\n",
        "    else:\n",
        "        return 2  # Away win\n",
        "\n",
        "# Apply the FTR calculation to each row in the DataFrame\n",
        "combined_leagues_df['FTR'] = combined_leagues_df.apply(\n",
        "    lambda row: calculate_ftr(row['home_team_goal_count'], row['away_team_goal_count']), axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "C1mtBhb_ANlt"
      },
      "id": "C1mtBhb_ANlt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already loaded cleaned_matches_data_df\n",
        "print(cleaned_matches_data_df.describe())\n",
        "\n",
        "# Histograms for continuous variables in matches data\n",
        "cleaned_matches_data_df[['home_team_goal_count', 'away_team_goal_count']].hist(bins=15, figsize=(15, 6))\n",
        "\n",
        "# Scatter Plot for relationships in matches data\n",
        "plt.scatter(cleaned_matches_data_df['home_team_shots'], cleaned_matches_data_df['home_team_goal_count'])\n",
        "plt.xlabel('Home Team Shots')\n",
        "plt.ylabel('Home Team Goals')\n",
        "plt.title('Home Team Shots vs Goals')\n",
        "\n",
        "# Correlation Heatmap for matches data\n",
        "corr_matches = cleaned_matches_data_df.corr()\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(corr_matches, annot=True, fmt=\".2f\")\n"
      ],
      "metadata": {
        "id": "Kp4LKrH9CAOS"
      },
      "id": "Kp4LKrH9CAOS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if 'date' column exists in the DataFrame\n",
        "if 'date_GMT' in df.columns:\n",
        "    print(\"Column 'date_GMT' exists.\")\n",
        "else:\n",
        "    print(\"Column 'date_GMT' does not exist.\")\n"
      ],
      "metadata": {
        "id": "huI9k74HCuvw"
      },
      "id": "huI9k74HCuvw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Sorting data by date instead of timestamp\n",
        "df.sort_values(by='date_GMT', inplace=True)\n"
      ],
      "metadata": {
        "id": "3zgwXNAVCw0Z"
      },
      "id": "3zgwXNAVCw0Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Splitting data based on a specific date\n",
        "train_df = df[df['date_GMT'] < '2023-11-30']\n",
        "test_df = df[df['date_GMT'] >= '2023-11-30']"
      ],
      "metadata": {
        "id": "CP-i3Pb-Cy_C"
      },
      "id": "CP-i3Pb-Cy_C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'head_to_head' in df.columns:\n",
        "    print(\"Column 'head_to_head' exists.\")\n",
        "else:\n",
        "    print(\"Column 'head_to_head' does not exist.\")\n"
      ],
      "metadata": {
        "id": "8jM_G2TcC3iZ"
      },
      "id": "8jM_G2TcC3iZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a function that can calculate head to head statistics\n",
        "def calculate_head_to_head(home_team, away_team):\n",
        "    # This function would return head to head stats like {'home_wins': X, 'away_wins': Y, 'draws': Z}\n",
        "    # based on historical data of matches between the two teams.\n",
        "    pass\n",
        "\n",
        "# Apply the function to each row in the DataFrame\n",
        "df['head_to_head'] = df.apply(lambda row: calculate_head_to_head(row['home_team_name'], row['away_team_name']), axis=1)"
      ],
      "metadata": {
        "id": "W0W_rqKAC3lV"
      },
      "id": "W0W_rqKAC3lV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update categorical and numeric features\n",
        "categorical_features = ['league']\n",
        "numeric_features = [col for col in df.columns if col not in categorical_features + ['head_to_head']]\n",
        "\n",
        "# Proceed with your preprocessing steps as before\n"
      ],
      "metadata": {
        "id": "pPbdKtUBC3np"
      },
      "id": "pPbdKtUBC3np",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the DataFrame\n",
        "print(\"First few rows of the DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display summary statistics of the DataFrame\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Display the data types of each column\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)\n"
      ],
      "metadata": {
        "id": "oaC2VO39C3qZ"
      },
      "id": "oaC2VO39C3qZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null values in each column\n",
        "print(\"\\nNull Value Counts:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check for unique values in a specific column (replace 'column_name' with actual column name)\n",
        "print(\"\\nUnique Values in a column:\")\n",
        "print(df['column_name'].unique())\n"
      ],
      "metadata": {
        "id": "p14IlCy1DAya"
      },
      "id": "p14IlCy1DAya",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['goal_difference'] = df['home_team_goal_count'] - df['away_team_goal_count']"
      ],
      "metadata": {
        "id": "2Z3FFVFoDGQ3"
      },
      "id": "2Z3FFVFoDGQ3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['combined_team_form'] = (df['home_team_form'] + df['away_team_form']) / 2"
      ],
      "metadata": {
        "id": "WMFtuYuXDA1Q"
      },
      "id": "WMFtuYuXDA1Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['date_GMT'] = pd.to_datetime(df['date_GMT'])\n",
        "df['day_of_week'] = df['date_GMT'].dt.day_name()\n",
        "df['time_of_day'] = df['date_GMT'].dt.hour"
      ],
      "metadata": {
        "id": "4GcC_tw0DA3v"
      },
      "id": "4GcC_tw0DA3v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['date_GMT'] = pd.to_datetime(df['date_GMT'])\n"
      ],
      "metadata": {
        "id": "crPhxSAVDA6T"
      },
      "id": "crPhxSAVDA6T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UogrLHeeDb2-"
      },
      "id": "UogrLHeeDb2-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA SPLIT FOR TRAINING AND PREDICTION:"
      ],
      "metadata": {
        "id": "19WXpLRIDcGg"
      },
      "id": "19WXpLRIDcGg"
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "id": "fcMBfk_VDA8f"
      },
      "id": "fcMBfk_VDA8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cutoff_date = pd.Timestamp('2023-11-30')\n",
        "train_data = df[df['date_GMT'] < cutoff_date]\n",
        "test_data = df[df['date_GMT'] >= cutoff_date]\n"
      ],
      "metadata": {
        "id": "8CWk_SVsDQkY"
      },
      "id": "8CWk_SVsDQkY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data.drop('FTR', axis=1)\n",
        "y_train = train_data['FTR']\n",
        "X_test = test_data.drop('FTR', axis=1)\n",
        "y_test = test_data['FTR']\n"
      ],
      "metadata": {
        "id": "tTJ46m48DQoH"
      },
      "id": "tTJ46m48DQoH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data.drop('FTR', axis=1)\n",
        "y_train = train_data['FTR']\n",
        "X_test = test_data.drop('FTR', axis=1)\n",
        "y_test = test_data['FTR']"
      ],
      "metadata": {
        "id": "jqj6_Oa2DX5R"
      },
      "id": "jqj6_Oa2DX5R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "id": "ooia8jsoDQrS"
      },
      "id": "ooia8jsoDQrS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X = cleaned_matches_data_df[features]\n",
        "y = cleaned_matches_data_df['FTR']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n"
      ],
      "metadata": {
        "id": "Whu-nVNkEGVV"
      },
      "id": "Whu-nVNkEGVV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(df, columns=['home_team_name', 'away_team_name', 'league', 'referee', 'stadium_name'])"
      ],
      "metadata": {
        "id": "NBN9-8r1Ecii"
      },
      "id": "NBN9-8r1Ecii",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['date_GMT', 'home_team_goal_timings', 'away_team_goal_timings', 'head_to_head'], axis=1)\n"
      ],
      "metadata": {
        "id": "4yZAfMRpEh2w"
      },
      "id": "4yZAfMRpEh2w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.get_dummies(df, columns=['status', 'day_of_week'])"
      ],
      "metadata": {
        "id": "H1q41leiEkC-"
      },
      "id": "H1q41leiEkC-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=5)\n",
        "print(f\"Cross-validated scores: {scores}\")\n"
      ],
      "metadata": {
        "id": "93qOIp7AEouN"
      },
      "id": "93qOIp7AEouN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'favorite_based_on_odds' is the column that shows the expected winner based on odds\n",
        "cleaned_matches_data_df['odds_accuracy'] = (cleaned_matches_data_df['favorite_based_on_odds'] == cleaned_matches_data_df['FTR']).astype(int)\n"
      ],
      "metadata": {
        "id": "-5liS-kREpfx"
      },
      "id": "-5liS-kREpfx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = ['home_team_name', 'away_team_name', 'referee', 'stadium_name', 'league']\n",
        "X_train = pd.get_dummies(X_train, columns=categorical_columns)\n"
      ],
      "metadata": {
        "id": "ZNR1L8xDEuB3"
      },
      "id": "ZNR1L8xDEuB3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "id": "DsteVa1uEwJ6"
      },
      "id": "DsteVa1uEwJ6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_favorite(row):\n",
        "    home_odds = row['odds_ft_home_team_win']\n",
        "    draw_odds = row['odds_ft_draw']\n",
        "    away_odds = row['odds_ft_away_team_win']\n",
        "\n",
        "    if min(home_odds, draw_odds, away_odds) == home_odds:\n",
        "        return 'Home'\n",
        "    elif min(home_odds, draw_odds, away_odds) == away_odds:\n",
        "        return 'Away'\n",
        "    else:\n",
        "        return 'Draw'\n",
        "\n",
        "# Apply the function to each row\n",
        "cleaned_matches_data_df['favorite_based_on_odds'] = cleaned_matches_data_df.apply(determine_favorite, axis=1)"
      ],
      "metadata": {
        "id": "Y-sad5d7Ey6Z"
      },
      "id": "Y-sad5d7Ey6Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D3Qwo7wXEzvu"
      },
      "id": "D3Qwo7wXEzvu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Initialize the model\n",
        "model = XGBClassifier()\n",
        "\n",
        "# Fit the model to your training data\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "lIqJ2Fw8E2GY"
      },
      "id": "lIqJ2Fw8E2GY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.dtypes)"
      ],
      "metadata": {
        "id": "DBuGrm3fE6VF"
      },
      "id": "DBuGrm3fE6VF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Proceed with evaluating the model\n"
      ],
      "metadata": {
        "id": "zhhdPhIJE67J"
      },
      "id": "zhhdPhIJE67J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Initialize the model\n",
        "model = XGBClassifier()\n",
        "\n",
        "# Fit the model to your training data\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "XZL1zax2E9Qp"
      },
      "id": "XZL1zax2E9Qp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluating the model\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "VcWaUW2GE_mw"
      },
      "id": "VcWaUW2GE_mw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting to Unix timestamp\n",
        "X['date_GMT'] = X['date_GMT'].astype(int) / 10**9"
      ],
      "metadata": {
        "id": "I_XEcCQ-FCWo"
      },
      "id": "I_XEcCQ-FCWo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_columns = ['status', 'home_team_goal_timings', 'away_team_goal_timings', 'head_to_head', 'day_of_week']\n",
        "X = pd.get_dummies(X, columns=object_columns)\n"
      ],
      "metadata": {
        "id": "8rIgy_DeFG_Q"
      },
      "id": "8rIgy_DeFG_Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "model = XGBClassifier(enable_categorical=True)\n",
        "scores = cross_val_score(model, X, y, cv=5, error_score='raise')\n",
        "print(\"Cross-validated scores:\", scores)\n",
        "print(\"Average score:\", scores.mean())"
      ],
      "metadata": {
        "id": "sw-uMaMFFHxb"
      },
      "id": "sw-uMaMFFHxb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = XGBClassifier()  # Replace with your model and parameters\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "6SiNUpiOFMFj"
      },
      "id": "6SiNUpiOFMFj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.describe(include='all'))\n"
      ],
      "metadata": {
        "id": "9_sTLmS6FPJ3"
      },
      "id": "9_sTLmS6FPJ3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Assuming y_test and y_pred are your test labels and model predictions\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "kccmnRkQFP7A"
      },
      "id": "kccmnRkQFP7A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=5)  # Replace X and y with your features and labels\n",
        "print(\"Cross-validation scores:\", scores)"
      ],
      "metadata": {
        "id": "wP6gMi5FFSue"
      },
      "id": "wP6gMi5FFSue",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"Dataset info:\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "t5V9E4V2FVJ5"
      },
      "id": "t5V9E4V2FVJ5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Comparing training and validation accuracy\n",
        "train_accuracy = ...  # Your training accuracy\n",
        "validation_accuracy = ...  # Your validation accuracy\n",
        "print(\"Training accuracy:\", train_accuracy)\n",
        "print(\"Validation accuracy:\", validation_accuracy)\n"
      ],
      "metadata": {
        "id": "P551670BFXeU"
      },
      "id": "P551670BFXeU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = XGBClassifier()  # Replace with your specific model parameters\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "h3OM0WxMFbCt"
      },
      "id": "h3OM0WxMFbCt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your original DataFrame\n",
        "# And it has columns like 'home_team_name', 'away_team_name', 'match_outcome'\n",
        "\n",
        "# Initialize columns\n",
        "df['home_team_recent_form'] = 0\n",
        "df['away_team_recent_form'] = 0\n",
        "\n",
        "# Iterate and calculate form (example for home team)\n",
        "for index, row in df.iterrows():\n",
        "    # Get last 3-5 matches for the home team\n",
        "    recent_matches = df[(df['home_team_name'] == row['home_team_name']) & (df.index < index)].tail(3)\n",
        "\n",
        "    # Calculate wins, draws, and losses\n",
        "    wins = len(recent_matches[recent_matches['FTR'] == 'Win'])\n",
        "    draws = len(recent_matches[recent_matches['FTR'] == 'Draw'])\n",
        "    losses = len(recent_matches[recent_matches['FTR'] == 'Loss'])\n",
        "\n",
        "    # Assign to the new column\n",
        "    df.at[index, 'home_team_recent_form'] = wins - losses  # Example formula\n",
        "\n",
        "# Repeat similar steps for the away team"
      ],
      "metadata": {
        "id": "_i6nLRq4FdYB"
      },
      "id": "_i6nLRq4FdYB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = pd.DataFrame(model.feature_importances_,\n",
        "                                   index=X_train.columns,\n",
        "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances)"
      ],
      "metadata": {
        "id": "QJa36ZNjFgwE"
      },
      "id": "QJa36ZNjFgwE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "id": "YgbM2TokFlOi"
      },
      "id": "YgbM2TokFlOi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the features of the cleaned matches data df.csv\n"
      ],
      "metadata": {
        "id": "j6uRKvPzFqci"
      },
      "id": "j6uRKvPzFqci"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "print(df.columns)\n",
        "\n",
        "Index(['timestamp', 'home_team_name', 'away_team_name', 'referee', 'Game Week',\n",
        "       'Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_ppg', 'away_ppg',\n",
        "       'home_team_goal_count', 'away_team_goal_count', 'total_goal_count',\n",
        "       'total_goals_at_half_time', 'home_team_goal_count_half_time',\n",
        "       'away_team_goal_count_half_time', 'home_team_corner_count',\n",
        "       'away_team_corner_count', 'home_team_yellow_cards',\n",
        "       'home_team_red_cards', 'away_team_yellow_cards', 'away_team_red_cards',\n",
        "       'home_team_first_half_cards', 'home_team_second_half_cards',\n",
        "       'away_team_first_half_cards', 'away_team_second_half_cards',\n",
        "       'home_team_shots', 'away_team_shots', 'home_team_shots_on_target',\n",
        "       'away_team_shots_on_target', 'home_team_shots_off_target',\n",
        "       'away_team_shots_off_target', 'home_team_fouls', 'away_team_fouls',\n",
        "       'home_team_possession', 'away_team_possession',\n",
        "       'Home Team Pre-Match xG', 'Away Team Pre-Match xG', 'team_a_xg',\n",
        "       'team_b_xg', 'average_goals_per_match_pre_match',\n",
        "       'btts_percentage_pre_match', 'over_15_percentage_pre_match',\n",
        "       'over_25_percentage_pre_match', 'over_35_percentage_pre_match',\n",
        "       'over_45_percentage_pre_match', 'over_15_HT_FHG_percentage_pre_match',\n",
        "       'over_05_HT_FHG_percentage_pre_match',\n",
        "       'over_15_2HG_percentage_pre_match', 'over_05_2HG_percentage_pre_match',\n",
        "       'average_corners_per_match_pre_match',\n",
        "       'average_cards_per_match_pre_match', 'odds_ft_home_team_win',\n",
        "       'odds_ft_draw', 'odds_ft_away_team_win', 'odds_ft_over15',\n",
        "       'odds_ft_over25', 'odds_ft_over35', 'odds_ft_over45', 'odds_btts_yes',\n",
        "       'odds_btts_no', 'stadium_name', 'league', 'FTR', 'home_team_form',\n",
        "       'away_team_form', 'home_wins_head_to_head', 'away_wins_head_to_head',\n",
        "       'draws_head_to_head', 'goal_difference', 'combined_team_form',\n",
        "       'time_of_day', 'status_complete', 'status_incomplete',\n",
        "       'day_of_week_Thursday', 'day_of_week_Tuesday', 'home_team_recent_form',\n",
        "       'away_team_recent_form'],\n",
        "      dtype='object')"
      ],
      "metadata": {
        "id": "j5BCXosdFttT"
      },
      "id": "j5BCXosdFttT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training the model\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions and evaluating the model\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "RRKXu6buFzd-"
      },
      "id": "RRKXu6buFzd-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Using cross-validation to assess model performance\n",
        "scores = cross_val_score(model, X, y, cv=5)\n",
        "print(\"Cross-validated scores:\", scores)"
      ],
      "metadata": {
        "id": "yxFvMd-fF12X"
      },
      "id": "yxFvMd-fF12X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = pd.DataFrame(model.feature_importances_,\n",
        "                                   index=X_train.columns,\n",
        "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
        "print(feature_importances)\n"
      ],
      "metadata": {
        "id": "NyGjWpbYF2Sv"
      },
      "id": "NyGjWpbYF2Sv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming feature_importances is your DataFrame with feature importances\n",
        "zero_importance_features = feature_importances[feature_importances['importance'] == 0].index\n",
        "\n",
        "# Drop these features from your dataset\n",
        "X = X.drop(zero_importance_features, axis=1)\n"
      ],
      "metadata": {
        "id": "MtcPo1eVF5_B"
      },
      "id": "MtcPo1eVF5_B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = cross_val_score(model, X, y, cv=5)\n",
        "print(\"Cross-validated scores:\", scores)\n"
      ],
      "metadata": {
        "id": "feHr9C40F8Rp"
      },
      "id": "feHr9C40F8Rp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K7sSNvnDF9EL"
      },
      "id": "K7sSNvnDF9EL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "316a76b2",
      "metadata": {
        "id": "316a76b2"
      },
      "source": [
        "## Creating a Reduced CSV File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "898f0fe8",
      "metadata": {
        "id": "898f0fe8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Creating a Reduced CSV File\n",
        "# (Code for creating a reduced CSV file will be added here)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/cleaned_matches_data_df.csv'  # Update with your file's path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Display DataFrame information\n",
        "print(df.info())\n",
        "\n",
        "# Check summary statistics\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "fAbED9NQGFLy"
      },
      "id": "fAbED9NQGFLy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this next function sorts by fileter for a specific data, automate the update of this function accordingly."
      ],
      "metadata": {
        "id": "AfXGwrP5GJ-9"
      },
      "id": "AfXGwrP5GJ-9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill NA values in 'date_GMT' with a placeholder\n",
        "df['date_GMT'].fillna('No Date', inplace=True)\n",
        "\n",
        "# Filter for matches on November 28th and 29th, 2023\n",
        "matches_nov_28_29 = df[df['date_GMT'].str.contains('Nov 28 2023|Nov 29 2023')]\n"
      ],
      "metadata": {
        "id": "3egFkTbrGGEp"
      },
      "id": "3egFkTbrGGEp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "model_file_path = '/content/trained_xgboost_model.pkl'  # Update this to the correct path\n",
        "\n",
        "with open(model_file_path, 'rb') as file:\n",
        "    xgboost_model = pickle.load(file)\n"
      ],
      "metadata": {
        "id": "FczkGxJPGTgS"
      },
      "id": "FczkGxJPGTgS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "id": "gpogjaBwGV42"
      },
      "id": "gpogjaBwGV42",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated list of features to drop\n",
        "features_to_drop = ['timestamp', 'home_team_name', 'away_team_name']\n",
        "\n",
        "# Drop the features\n",
        "df = df.drop(features_to_drop, axis=1)\n",
        "\n",
        "# Define your features (X) and target variable (y)\n",
        "X = df.drop('FTR_encoded', axis=1)  # Assuming 'FTR_encoded' is your target column\n",
        "y = df['FTR']"
      ],
      "metadata": {
        "id": "OatZExO3GWkM"
      },
      "id": "OatZExO3GWkM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the target variable\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Now y_encoded contains the encoded labels as integers"
      ],
      "metadata": {
        "id": "M76zpDBVGWnO"
      },
      "id": "M76zpDBVGWnO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "file_path = '/content/cleaned_matches_data_with_features.csv'  # Path to your file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows to confirm it's loaded correctly\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "IGRPf8cWGcXq"
      },
      "id": "IGRPf8cWGcXq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cutoff_date = '2023-11-30'\n",
        "train_data = df[df['date_GMT'] < cutoff_date]\n",
        "test_data = df[df['date_GMT'] >= cutoff_date]\n"
      ],
      "metadata": {
        "id": "qUds-_sQH5sg"
      },
      "id": "qUds-_sQH5sg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cutoff_date = '2023-11-30'\n",
        "train_data = df[df['date_GMT'] < cutoff_date]\n",
        "test_data = df[df['date_GMT'] >= cutoff_date]\n",
        "\n",
        "Results Visualization Visualize the results of the model."
      ],
      "metadata": {
        "id": "UiQSF-xdH-lT"
      },
      "id": "UiQSF-xdH-lT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c6jiuBa9H_T_"
      },
      "id": "c6jiuBa9H_T_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results Visualization Visualize the results of the model."
      ],
      "metadata": {
        "id": "9upBB0TGIKvQ"
      },
      "id": "9upBB0TGIKvQ"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R3jTGf3-ILvJ"
      },
      "id": "R3jTGf3-ILvJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns that won't be used as features\n",
        "columns_to_drop = ['timestamp', 'date_GMT', 'status', 'referee', 'stadium_name', 'league']\n",
        "X_train = train_data.drop(columns=columns_to_drop + ['FTR'], axis=1)\n",
        "y_train = train_data['FTR']\n",
        "X_test = test_data.drop(columns=columns_to_drop + ['FTR'], axis=1)\n",
        "y_test = test_data['FTR']\n"
      ],
      "metadata": {
        "id": "A4cmKxF724OI"
      },
      "execution_count": null,
      "outputs": [],
      "id": "A4cmKxF724OI"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/cleaned_matches_data_with_features.csv')\n",
        "\n",
        "# Convert 'date_GMT' to a datetime object\n",
        "df['date_GMT'] = pd.to_datetime(df['date_GMT'])\n",
        "\n",
        "# Define your cutoff date\n",
        "cutoff_date = pd.Timestamp('2023-11-30')\n",
        "\n",
        "# Split the data\n",
        "train_data = df[df['date_GMT'] < cutoff_date]\n",
        "test_data = df[df['date_GMT'] >= cutoff_date]\n",
        "\n",
        "# Check if data splitting is correct\n",
        "print(\"Training data shape:\", train_data.shape)\n",
        "print(\"Testing data shape:\", test_data.shape)\n",
        "\n",
        "# Proceed with feature selection and model training\n"
      ],
      "metadata": {
        "id": "sQVqmlY2ITCw"
      },
      "id": "sQVqmlY2ITCw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Selecting features for the model\n",
        "feature_columns = ['Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_team_goal_count', 'away_team_goal_count', 'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match', 'odds_ft_home_team_win', 'odds_ft_draw', 'odds_ft_away_team_win']\n",
        "target_column = 'FTR'  # Replace with your target column\n",
        "\n",
        "# Splitting the features and target\n",
        "X_train = train_data[feature_columns]\n",
        "y_train = train_data[target_column]\n",
        "X_test = test_data[feature_columns]\n",
        "y_test = test_data[target_column]\n",
        "\n",
        "# Defining preprocessing for numeric and categorical features\n",
        "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Creating a pipeline with preprocessing and model\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', LogisticRegression())])\n",
        "\n",
        "# Training the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predicting on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Evaluating the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "6IDkFI9aITrk"
      },
      "id": "6IDkFI9aITrk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'cleaned_matches_data_with_features.csv' is loaded into 'df'\n",
        "# Replace 'features_list' with the list of feature column names you want to include\n",
        "features_list =  ['Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_team_goal_count', 'away_team_goal_count', 'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match', 'odds_ft_home_team_win', 'odds_ft_draw', 'odds_ft_away_team_win']\n",
        "X = df[features_list]\n",
        "y = df['FTR']  # Or your target column\n",
        "\n",
        "# Now run the cross-validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "cv_scores = cross_val_score(model, X, y, cv=5)\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean CV score:\", cv_scores.mean())"
      ],
      "metadata": {
        "id": "2fp-MhI1IXf2"
      },
      "id": "2fp-MhI1IXf2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Features:\", X_train.columns.tolist())\n",
        "print(\"Testing Features:\", X_test.columns.tolist())"
      ],
      "metadata": {
        "id": "L2-5wOxtIbBC"
      },
      "id": "L2-5wOxtIbBC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Compare feature lists\n",
        "print(\"Features in X_train:\", X_train.columns.tolist())\n",
        "print(\"\\nFeatures in X_test:\", X_test.columns.tolist())\n",
        "\n",
        "# Step 2: Identify and add missing features in X_test\n",
        "missing_features = [feature for feature in X_train.columns if feature not in X_test.columns]\n",
        "for feature in missing_features:\n",
        "    X_test[feature] = 0  # or any other appropriate default value\n",
        "\n",
        "# Step 3: Align feature order in X_test to match X_train\n",
        "X_test = X_test[X_train.columns]\n",
        "\n",
        "# Step 4: Check and align data types if necessary\n",
        "for column in X_train.columns:\n",
        "    if X_train[column].dtype != X_test[column].dtype:\n",
        "        X_test[column] = X_test[column].astype(X_train[column].dtype)\n",
        "\n",
        "# Now try predicting again\n",
        "try:\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(\"Prediction successful.\")\n",
        "except Exception as e:\n",
        "    print(\"Error during prediction:\", e)\n",
        "\n",
        "# If the prediction is successful, you can proceed with evaluation\n",
        "if 'y_pred' in locals():\n",
        "    print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Cq4AJgxxIdhO"
      },
      "id": "Cq4AJgxxIdhO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with the current set of features in X_train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "LqT-2JftIi7m"
      },
      "id": "LqT-2JftIi7m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of classes in the test set\n",
        "print(y_test.value_counts())\n"
      ],
      "metadata": {
        "id": "Hh1w7sgWIm4x"
      },
      "id": "Hh1w7sgWIm4x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lXJlWb7bIpvH"
      },
      "id": "lXJlWb7bIpvH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/content/drive/My Drive/94_betting_model'\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "# Now save the model\n",
        "joblib.dump(model, folder_path + '/94_betting_model.pkl')\n"
      ],
      "metadata": {
        "id": "2MwYLNPqIsnW"
      },
      "id": "2MwYLNPqIsnW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_matches_data_df.to_csv(folder_path + '/cleaned_matches_data_df.csv', index=False)\n",
        "# Similarly for other DataFrames or relevant objects\n"
      ],
      "metadata": {
        "id": "M4Ose6a5IvKS"
      },
      "id": "M4Ose6a5IvKS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cleaned_matches_data_df.head())"
      ],
      "metadata": {
        "id": "pEDBbghrIxwB"
      },
      "id": "pEDBbghrIxwB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/94_betting_model'  # Replace with your folder path"
      ],
      "metadata": {
        "id": "4FhvgxnuI0BP"
      },
      "id": "4FhvgxnuI0BP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_matches_data_df.to_csv(folder_path + '/cleaned_matches_data_df.csv', index=False)"
      ],
      "metadata": {
        "id": "mK9Nflo3I3Je"
      },
      "id": "mK9Nflo3I3Je",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Add predictions to the test DataFrame\n",
        "test_data['Predicted_FTR'] = y_pred\n",
        "\n",
        "# Filter the DataFrame for the specific dates\n",
        "games_on_nov_30 = test_data[test_data['date_GMT'].dt.date == pd.to_datetime('2023-11-30').date()]\n",
        "games_on_dec_01 = test_data[test_data['date_GMT'].dt.date == pd.to_datetime('2023-12-01').date()]\n",
        "\n",
        "# Display the predictions for these dates\n",
        "print(\"Predictions for Games on November 30, 2023:\")\n",
        "print(games_on_nov_30[['home_team_name', 'away_team_name', 'Predicted_FTR']])\n",
        "\n",
        "print(\"\\nPredictions for Games on December 01, 2023:\")\n",
        "print(games_on_dec_01[['home_team_name', 'away_team_name', 'Predicted_FTR']])"
      ],
      "metadata": {
        "id": "sn61-WsyI6JV"
      },
      "id": "sn61-WsyI6JV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cXFyCDCYI86-"
      },
      "id": "cXFyCDCYI86-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOTHER STACK OF PREDICTION CODE: THIS MIGHT BE THE ONE"
      ],
      "metadata": {
        "id": "8jlSNeVQJD0W"
      },
      "id": "8jlSNeVQJD0W"
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_matches_data_df = pd.read_csv('/content/cleaned_matches_data_df.csv')"
      ],
      "metadata": {
        "id": "p6cqW7iIJMKC"
      },
      "id": "p6cqW7iIJMKC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_matches_data_df.to_csv(folder_path + '/cleaned_matches_data_df.csv', index=False)\n"
      ],
      "metadata": {
        "id": "_Wce866lJHcW"
      },
      "id": "_Wce866lJHcW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/My Drive/94_betting_model'\n"
      ],
      "metadata": {
        "id": "yOYbtlYGJLbO"
      },
      "id": "yOYbtlYGJLbO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for unique values or formats in 'date_GMT'\n",
        "print(df['date_GMT'].unique())\n",
        "\n",
        "# Option 1: Drop rows where 'date_GMT' is not in a standard date format\n",
        "# df = df[df['date_GMT'] != 'No Date present']\n",
        "\n",
        "# Option 2: Replace non-standard dates with a default date or NaN\n",
        "# df['date_GMT'] = df['date_GMT'].replace('No Date present', pd.NaT)  # or some default date\n",
        "\n",
        "# After cleaning, convert 'date_GMT' to datetime\n",
        "X['date_GMT'] = pd.to_datetime(X['date_GMT'], errors='coerce')  # 'coerce' will set invalid parsing as NaT"
      ],
      "metadata": {
        "id": "JDlUPuqSJRhS"
      },
      "id": "JDlUPuqSJRhS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'date_GMT' to datetime and then extract numerical features\n",
        "X['date_GMT'] = pd.to_datetime(X['date_GMT'], errors='coerce')\n",
        "X['year'] = X['date_GMT'].dt.year\n",
        "X['month'] = X['date_GMT'].dt.month\n",
        "X['day'] = X['date_GMT'].dt.day\n",
        "X = X.drop('date_GMT', axis=1)  # Drop the original 'date_GMT' column\n",
        "\n",
        "# Ensure 'FTR' is not in your features DataFrame\n",
        "X = X.drop('FTR', axis=1, errors='ignore')"
      ],
      "metadata": {
        "id": "8x6A0P9fJVj0"
      },
      "id": "8x6A0P9fJVj0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'date_GMT' to datetime, setting errors to 'coerce' will turn invalid parsing into NaT\n",
        "df['date_GMT'] = pd.to_datetime(df['date_GMT'], errors='coerce')\n",
        "\n",
        "# Drop rows where 'date_GMT' is NaT (not a time)\n",
        "df = df.dropna(subset=['date_GMT'])\n"
      ],
      "metadata": {
        "id": "iqtE53vAJaMo"
      },
      "id": "iqtE53vAJaMo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Now, use classification_report to evaluate your model\n",
        "print(classification_report(y_test_encoded, y_pred))\n"
      ],
      "metadata": {
        "id": "EHnDQi0dJcjI"
      },
      "id": "EHnDQi0dJcjI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ],
      "metadata": {
        "id": "8dO3CQQ0JcmO"
      },
      "id": "8dO3CQQ0JcmO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract year, month, and day as separate features\n",
        "X_train['year'] = X_train['date_GMT'].dt.year\n",
        "X_train['month'] = X_train['date_GMT'].dt.month\n",
        "X_train['day'] = X_train['date_GMT'].dt.day\n",
        "\n",
        "X_test['year'] = X_test['date_GMT'].dt.year\n",
        "X_test['month'] = X_test['date_GMT'].dt.month\n",
        "X_test['day'] = X_test['date_GMT'].dt.day\n",
        "\n",
        "# Drop the original 'date_GMT' column\n",
        "X_train = X_train.drop('date_GMT', axis=1)\n",
        "X_test = X_test.drop('date_GMT', axis=1)\n"
      ],
      "metadata": {
        "id": "hyyr33QSJcpC"
      },
      "id": "hyyr33QSJcpC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "Hocr9WtlJmV8"
      },
      "id": "Hocr9WtlJmV8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'date_GMT' to datetime and then extract year, month, and day\n",
        "X_train['year'] = X_train['date_GMT'].dt.year\n",
        "X_train['month'] = X_train['date_GMT'].dt.month\n",
        "X_train['day'] = X_train['date_GMT'].dt.day\n",
        "X_train = X_train.drop('date_GMT', axis=1)  # Drop the original 'date_GMT' column\n",
        "\n",
        "# Repeat for X_test if you have a test set\n",
        "X_test['year'] = X_test['date_GMT'].dt.year\n",
        "X_test['month'] = X_test['date_GMT'].dt.month\n",
        "X_test['day'] = X_test['date_GMT'].dt.day\n",
        "X_test = X_test.drop('date_GMT', axis=1)"
      ],
      "metadata": {
        "id": "qwDWrRBDJo51"
      },
      "id": "qwDWrRBDJo51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X_train and y_train are already defined and preprocessed\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Z4dNBGAaJsa9"
      },
      "id": "Z4dNBGAaJsa9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X_test and y_test are your testing data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "KPFu2d44Jvkn"
      },
      "id": "KPFu2d44Jvkn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'model' is your trained XGBoost model\n",
        "feature_importances = model.feature_importances_\n",
        "\n",
        "# Assuming 'X_train' is your training data with feature names\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# Create a DataFrame to display feature names and their importances\n",
        "importances_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance in descending order\n",
        "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display the feature importances\n",
        "print(importances_df)"
      ],
      "metadata": {
        "id": "cxAmFwtdJyZs"
      },
      "id": "cxAmFwtdJyZs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['date_GMT'] = pd.to_datetime(df['date_GMT'])\n"
      ],
      "metadata": {
        "id": "056li7f9J1ZV"
      },
      "id": "056li7f9J1ZV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THE SPLIT NEEDS TO BE AUTOMATED BASED ON PRESENT DATE OF PREDICTION CODE RUNNING:"
      ],
      "metadata": {
        "id": "dsjO_j8vJ8g_"
      },
      "id": "dsjO_j8vJ8g_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data: Training data is before November 28th\n",
        "train_data = df[df['date_GMT'] < '2023-11-28']\n",
        "\n",
        "# Testing data is on or after November 28th\n",
        "test_data = df[df['date_GMT'] >= '2023-11-28']\n"
      ],
      "metadata": {
        "id": "1RpMOyNlJ5lD"
      },
      "id": "1RpMOyNlJ5lD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'FTR' is the target variable\n",
        "X_train = train_data.drop(['FTR', 'date_GMT'], axis=1)  # Dropping 'date_GMT' if not used as a feature\n",
        "y_train = train_data['FTR']\n",
        "\n",
        "X_test = test_data.drop(['FTR', 'date_GMT'], axis=1)\n",
        "y_test = test_data['FTR']"
      ],
      "metadata": {
        "id": "w2QBqmVBKDE9"
      },
      "id": "w2QBqmVBKDE9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"First few rows of X_train:\\n\", X_train.head())\n"
      ],
      "metadata": {
        "id": "5qoD_euWKFnY"
      },
      "id": "5qoD_euWKFnY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your data into a DataFrame\n",
        "df = pd.read_csv('/content/cleaned_matches_data_with_features.csv')\n",
        "\n",
        "# Data cleaning and preprocessing steps\n",
        "# ...\n",
        "\n",
        "# Convert 'date_GMT' to datetime for filtering\n",
        "df['date_GMT'] = pd.to_datetime(df['date_GMT'])\n",
        "\n",
        "# Split the data\n",
        "train_data = df[df['date_GMT'] < '2023-11-28']\n",
        "test_data = df[df['date_GMT'] >= '2023-11-28']\n",
        "\n",
        "# Prepare features and labels\n",
        "X_train = train_data.drop(['FTR', 'date_GMT'], axis=1)  # Assuming 'FTR' is your target\n",
        "y_train = train_data['FTR']\n",
        "X_test = test_data.drop(['FTR', 'date_GMT'], axis=1)\n",
        "y_test = test_data['FTR']"
      ],
      "metadata": {
        "id": "sA3VOuNyKLr0"
      },
      "id": "sA3VOuNyKLr0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = ['status', 'home_team_name', 'away_team_name', 'referee',\n",
        "                    'home_team_goal_timings', 'away_team_goal_timings',\n",
        "                    'stadium_name', 'league', 'head_to_head']\n",
        "\n",
        "df = pd.get_dummies(df, columns=categorical_cols)\n"
      ],
      "metadata": {
        "id": "ZHHFjLclKOiH"
      },
      "id": "ZHHFjLclKOiH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "id": "_UQOmW2_KR1i"
      },
      "id": "_UQOmW2_KR1i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = [\n",
        "    'home_team_goal_count', 'away_team_shots', 'odds_ft_away_team_win',\n",
        "    'home_team_possession', 'home_team_shots', 'over_25_percentage_pre_match',\n",
        "    'team_a_xg', 'average_corners_per_match_pre_match', 'away_team_goal_count',\n",
        "    'away_team_shots_off_target', 'away_team_goal_count_half_time', 'home_ppg',\n",
        "    'away_team_shots_on_target', 'home_team_fouls', 'draws_head_to_head',\n",
        "    'average_home_possession', 'home_team_form', 'Home Team Pre-Match xG',\n",
        "    'odds_ft_over45', 'Pre-Match PPG (Home)', 'Pre-Match PPG (Away)',\n",
        "    'Game Week', 'home_team_shots_off_target', 'average_cards_per_match_pre_match'\n",
        "]\n"
      ],
      "metadata": {
        "id": "zxdUT65oKVpQ"
      },
      "id": "zxdUT65oKVpQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = [\n",
        "    'home_team_goal_count', 'away_team_shots', 'odds_ft_away_team_win',\n",
        "    'home_team_possession', 'home_team_shots', 'over_25_percentage_pre_match',\n",
        "    'team_a_xg', 'average_corners_per_match_pre_match', 'away_team_goal_count',\n",
        "    'away_team_shots_off_target', 'away_team_goal_count_half_time', 'home_ppg',\n",
        "    'away_team_shots_on_target', 'home_team_fouls',\n",
        "    'Home Team Pre-Match xG', 'odds_ft_over45', 'Pre-Match PPG (Home)',\n",
        "    'Pre-Match PPG (Away)', 'Game Week', 'home_team_shots_off_target',\n",
        "    'average_cards_per_match_pre_match'\n",
        "]"
      ],
      "metadata": {
        "id": "L56BsNzxKa2y"
      },
      "id": "L56BsNzxKa2y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[selected_features]\n",
        "y = df['FTR']  # Replace with your actual target column name\n",
        "\n",
        "# Continue with model training and evaluation\n",
        "# ..."
      ],
      "metadata": {
        "id": "u2ttmnSrKeMi"
      },
      "id": "u2ttmnSrKeMi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "# List all columns that are of object type, which are typically considered categorical\n",
        "categorical_features = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Print the list of categorical features\n",
        "print(\"Categorical Features:\", list(categorical_features))"
      ],
      "metadata": {
        "id": "FsZdvnB0Kghy"
      },
      "id": "FsZdvnB0Kghy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert 'birthday_GMT' to datetime and extract year\n",
        "df['birthday_GMT'] = pd.to_datetime(df['birthday_GMT'])\n",
        "df['birth_year'] = df['birthday_GMT'].dt.year\n",
        "\n",
        "# One-hot encode low cardinality categorical features\n",
        "df = pd.get_dummies(df, columns=['league', 'season', 'position', 'age_group'])\n",
        "\n",
        "# Label encode high cardinality features\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoders = {}\n",
        "for column in ['full_name', 'Current Club', 'nationality', 'player_id']:\n",
        "    label_encoders[column] = LabelEncoder()\n",
        "    df[column] = label_encoders[column].fit_transform(df[column])\n",
        "\n",
        "# Drop the original 'birthday_GMT' column\n",
        "df = df.drop('birthday_GMT', axis=1)\n",
        "\n",
        "# Now df is ready for model training"
      ],
      "metadata": {
        "id": "PuzCWsslKil0"
      },
      "id": "PuzCWsslKil0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "SHjs0GbZKlO2"
      },
      "id": "SHjs0GbZKlO2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Now you can use classification_report without any error\n",
        "print(classification_report(y_test_encoded, y_pred))\n"
      ],
      "metadata": {
        "id": "nortCS9GKoer"
      },
      "id": "nortCS9GKoer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your dataframe is named 'df' and the date_GMT column is named 'date_GMT'\n",
        "# Replace 'start_date' and 'end_date' with your specific date range\n",
        "\n",
        "start_date = '2023-11-28'\n",
        "end_date = '2023-12-10'\n",
        "\n",
        "# Filter the dataframe based on the date range\n",
        "df = df[(df['date_GMT'] >= start_date) & (df['date_GMT'] <= end_date)]\n",
        "\n",
        "# Display the filtered dataframe\n",
        "df"
      ],
      "metadata": {
        "id": "H_a5WPVrKt8E"
      },
      "id": "H_a5WPVrKt8E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataframe to a CSV file\n",
        "df.to_csv('filtered_data.csv', index=False)"
      ],
      "metadata": {
        "id": "XdwMBdAmKxW7"
      },
      "id": "XdwMBdAmKxW7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataframe to a CSV file\n",
        "df.to_csv('filtered_data.csv', index=False)\n",
        "\n",
        "# Download the CSV file\n",
        "from google.colab import files\n",
        "files.download('filtered_data.csv')"
      ],
      "metadata": {
        "id": "Ts6tldplK1Mp"
      },
      "id": "Ts6tldplK1Mp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G9iKu9OTK3g_"
      },
      "id": "G9iKu9OTK3g_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREDICTION CODE 3:"
      ],
      "metadata": {
        "id": "1QSMohr-K_Yw"
      },
      "id": "1QSMohr-K_Yw"
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Correct path to your saved XGBoost model\n",
        "xgboost_model_path = '/content/drive/My Drive/trained_xgboost_model.pkl'\n",
        "\n",
        "# Load the XGBoost model\n",
        "try:\n",
        "    with open(xgboost_model_path, 'rb') as file:\n",
        "        xgboost_model = pickle.load(file)\n",
        "    print(\"XGBoost model loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Model file not found. Please check the file path.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the XGBoost model: {e}\")\n"
      ],
      "metadata": {
        "id": "Hmdy4PG-K3j8"
      },
      "id": "Hmdy4PG-K3j8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "filter date accodring with present date of prediction running of test."
      ],
      "metadata": {
        "id": "gKdSmnJaLHqQ"
      },
      "id": "gKdSmnJaLHqQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame for matches on November 28th and 29th\n",
        "nov_28_29_matches = df[df['date_GMT'].str.contains('Nov 28 2023|Nov 29 2023', na=False)]\n",
        "\n",
        "# Display the first few rows to verify\n",
        "print(nov_28_29_matches.head())\n"
      ],
      "metadata": {
        "id": "91gcgKtpK3mk"
      },
      "id": "91gcgKtpK3mk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the feature set for prediction\n",
        "X_nov_28_29 = nov_28_29_matches[features]  # Assuming 'features' is a list of your model's feature names\n",
        "\n",
        "# Verify the prepared data\n",
        "print(X_nov_28_29.head())"
      ],
      "metadata": {
        "id": "zZmAdEVLK3pN"
      },
      "id": "zZmAdEVLK3pN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(model_file_path, 'wb') as file:\n",
        "    pickle.dump(model, file)\n"
      ],
      "metadata": {
        "id": "j8nYSZDNLSJx"
      },
      "id": "j8nYSZDNLSJx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your DataFrame\n",
        "df['FTR'] = (df['home_team_goal_count'] - df['away_team_goal_count']).apply(\n",
        "    lambda x: 'H' if x > 0 else ('D' if x == 0 else 'A')\n",
        ")\n"
      ],
      "metadata": {
        "id": "NwL82HJKLVkg"
      },
      "id": "NwL82HJKLVkg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature columns (excluding target-related columns)\n",
        "feature_columns = [col for col in df.columns if col not in ['home_team_goal_count', 'away_team_goal_count', 'FTR']]\n",
        "\n",
        "# Target column\n",
        "target_column = 'FTR'\n",
        "\n",
        "# Split the DataFrame into features (X) and target (y)\n",
        "X_train = df[feature_columns]\n",
        "y_train = df[target_column]"
      ],
      "metadata": {
        "id": "vsgIBq-ZLWLR"
      },
      "id": "vsgIBq-ZLWLR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Instantiate the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit and transform the 'FTR' column to numerical classes\n",
        "df['FTR_encoded'] = label_encoder.fit_transform(df['FTR'])\n",
        "\n",
        "# Define y_train using the encoded FTR column\n",
        "y_train = df['FTR_encoded']\n"
      ],
      "metadata": {
        "id": "gcueRADFLYVB"
      },
      "id": "gcueRADFLYVB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique values in y_train:\", set(y_train))\n"
      ],
      "metadata": {
        "id": "CuvlhmZOLajN"
      },
      "id": "CuvlhmZOLajN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming your trained model is stored in a variable named 'model'\n",
        "model_file_path = '/content/drive/My Drive/trained_xgboost_model.pkl'  # Adjust the path as needed\n",
        "\n",
        "# Save the model to a file\n",
        "with open(model_file_path, 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "3UA4_T_GLctV"
      },
      "id": "3UA4_T_GLctV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting the required features for prediction\n",
        "features_for_prediction = ['home_team_goal_count', 'away_team_shots', 'odds_ft_away_team_win']\n",
        "X_new = df_new[features_for_prediction]\n",
        "\n",
        "# Ensure X_new is preprocessed similarly to your training data\n",
        "# (Add any preprocessing steps here if required)"
      ],
      "metadata": {
        "id": "kjzg0idJLfh9"
      },
      "id": "kjzg0idJLfh9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the saved model file\n",
        "model_file_path = '/content/drive/My Drive/trained_xgboost_model.pkl'\n",
        "\n",
        "# Load the model\n",
        "with open(model_file_path, 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n"
      ],
      "metadata": {
        "id": "1T5C5VkeLhzq"
      },
      "id": "1T5C5VkeLhzq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost\n",
        "!pip install scikit-learn --upgrade"
      ],
      "metadata": {
        "id": "eV8sUW2VLlIc"
      },
      "id": "eV8sUW2VLlIc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Paths to your model files\n",
        "xgboost_model_path = '/content/drive/My Drive/trained_xgboost_model.pkl'\n",
        "betting_model_path = '/content/drive/My Drive/betting_model_v1.pkl'\n",
        "\n",
        "# Load the XGBoost model\n",
        "try:\n",
        "    with open(xgboost_model_path, 'rb') as file:\n",
        "        xgboost_model = pickle.load(file)\n",
        "    print(\"XGBoost model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the XGBoost model: {e}\")\n",
        "\n",
        "# Load the betting model\n",
        "try:\n",
        "    with open(betting_model_path, 'rb') as file:\n",
        "        betting_model = pickle.load(file)\n",
        "    print(\"Betting model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the betting model: {e}\")\n"
      ],
      "metadata": {
        "id": "Qw0GCIF9Ll3_"
      },
      "id": "Qw0GCIF9Ll3_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Correct path to your saved model\n",
        "model_file_path = '/content/drive/My Drive/trained_xgboost_model.pkl'\n",
        "\n",
        "# Load the model\n",
        "try:\n",
        "    with open(model_file_path, 'rb') as file:\n",
        "        loaded_model = pickle.load(file)\n",
        "except FileNotFoundError:\n",
        "    print(\"The specified model file does not exist at the provided path.\")"
      ],
      "metadata": {
        "id": "GIf6gjhsLoNx"
      },
      "id": "GIf6gjhsLoNx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming your model is named 'model' and has been trained\n",
        "model_file_path = '/content/drive/My Drive/trained_xgboost_model.pkl'\n",
        "\n",
        "# Save the trained model to a file\n",
        "with open(model_file_path, 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "RrO4OCfyLufC"
      },
      "id": "RrO4OCfyLufC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CHXgGpJNL2GE"
      },
      "id": "CHXgGpJNL2GE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Filtering for matches on a specific date (adjust the condition as needed)\n",
        "upcoming_matches = df[df['date_GMT'].str.contains('Upcoming_Date', na=False)]\n"
      ],
      "metadata": {
        "id": "skYC895u8QYo"
      },
      "execution_count": null,
      "outputs": [],
      "id": "skYC895u8QYo"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path for the new CSV file\n",
        "new_data_file_path = '/content/drive/My Drive/upcoming_matches.csv'  # Adjust the path as needed\n",
        "\n",
        "# Save the filtered data to a CSV file\n",
        "upcoming_matches.to_csv(new_data_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "_imC2L-j8UJn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "_imC2L-j8UJn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the new data for prediction\n",
        "df_new = pd.read_csv(new_data_file_path)\n",
        "\n",
        "# Prepare the features for prediction (ensure the same preprocessing as your training data)\n",
        "# ...\n",
        "\n",
        "# Load your trained model and make predictions\n",
        "# ...\n"
      ],
      "metadata": {
        "id": "LhKq49K48aIj"
      },
      "execution_count": null,
      "outputs": [],
      "id": "LhKq49K48aIj"
    },
    {
      "cell_type": "code",
      "source": [
        "# List of feature columns used in your model\n",
        "features = [\n",
        "    'home_team_goal_count', 'away_team_shots', 'odds_ft_away_team_win',\n",
        "    'home_team_possession', 'home_team_shots',\n",
        "    # ... (include all relevant features from your list)\n",
        "]\n",
        "\n",
        "# Prepare the feature set for the matches on Nov 28th and 29th\n",
        "X_nov_28_29 = matches_nov_28_29[features]\n"
      ],
      "metadata": {
        "id": "bNJVQC3aL9AZ"
      },
      "id": "bNJVQC3aL9AZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VW9dsiaAL9tv"
      },
      "id": "VW9dsiaAL9tv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "additional predictio viusaulisations:"
      ],
      "metadata": {
        "id": "Nd2L84kLMBUr"
      },
      "id": "Nd2L84kLMBUr"
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# Create a SHAP explainer and calculate SHAP values\n",
        "explainer = shap.Explainer(model, X_train)\n",
        "shap_values = explainer(X_train)\n",
        "\n",
        "# Summary plot\n",
        "shap.summary_plot(shap_values, X_train)\n"
      ],
      "metadata": {
        "id": "BIC_UZBxME8O"
      },
      "id": "BIC_UZBxME8O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EM5V9S1FMKPB"
      },
      "id": "EM5V9S1FMKPB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define a set of parameters to test\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    # ... add other parameters here\n",
        "}\n",
        "\n",
        "# Initialize the Grid Search\n",
        "grid_search = GridSearchCV(XGBClassifier(), param_grid, cv=3, scoring='accuracy')\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeL-mNOoUuuz",
        "outputId": "2d0df705-30b3-40b1-fc4d-838e01abe890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'learning_rate': 0.1, 'n_estimators': 100}\n"
          ]
        }
      ],
      "id": "QeL-mNOoUuuz"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Define a distribution of parameters to test\n",
        "param_dist = {\n",
        "    'n_estimators': randint(100, 500),\n",
        "    'learning_rate': uniform(0.01, 0.2),\n",
        "    # ... add other parameters here\n",
        "}\n",
        "\n",
        "# Initialize the Random Search\n",
        "random_search = RandomizedSearchCV(XGBClassifier(), param_dist, n_iter=25, cv=3, scoring='accuracy')\n",
        "\n",
        "# Perform Random Search\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best parameters:\", random_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k18CBod6U2OU",
        "outputId": "961e4c92-5f35-4733-adcf-246d51ff5e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'learning_rate': 0.04343105827061082, 'n_estimators': 201}\n"
          ]
        }
      ],
      "id": "k18CBod6U2OU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'match_outcome' is your target variable\n",
        "correlation_matrix = df.corr()\n",
        "print(correlation_matrix['FTR'].sort_values(ascending=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZZ4jfdRNFYM",
        "outputId": "a5c31823-dcbb-4d5b-b83c-3aa92b25e87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FTR                       1.000000\n",
            "status_incomplete         0.483909\n",
            "draws_head_to_head        0.436212\n",
            "Game Week                 0.369845\n",
            "timestamp                 0.356006\n",
            "                            ...   \n",
            "home_team_goal_count     -0.724397\n",
            "goal_difference          -0.782962\n",
            "home_wins_head_to_head   -1.000000\n",
            "home_team_recent_form          NaN\n",
            "away_team_recent_form          NaN\n",
            "Name: FTR, Length: 74, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-162-6b0ed6c10f35>:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  correlation_matrix = df.corr()\n"
          ]
        }
      ],
      "id": "8ZZ4jfdRNFYM"
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Selecting features and target\n",
        "features = ['home_team_recent_form', 'away_team_recent_form',\n",
        "            'average_home_possession', 'average_away_possession',\n",
        "            # ... include other relevant features\n",
        "           ]\n",
        "X = df[features]\n",
        "y = df['FTR']\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training the model\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFa1SIPfNOaj",
        "outputId": "c458231d-7671-4be4-9924-ef451b6e4bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.08      0.12        13\n",
            "           1       0.45      0.77      0.57        13\n",
            "\n",
            "    accuracy                           0.42        26\n",
            "   macro avg       0.35      0.42      0.34        26\n",
            "weighted avg       0.35      0.42      0.34        26\n",
            "\n"
          ]
        }
      ],
      "id": "PFa1SIPfNOaj"
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('home_wins_head_to_head', axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "OZPTM1QEOdkB"
      },
      "execution_count": null,
      "outputs": [],
      "id": "OZPTM1QEOdkB"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'favorite_based_on_odds' to a binary outcome similar to 'FTR'\n",
        "# Assuming 'Home' win is 0 and 'Away' win or 'Draw' is 1\n",
        "cleaned_matches_data_df['favorite_binary'] = (cleaned_matches_data_df['favorite_based_on_odds'] != 'Home').astype(int)\n",
        "\n",
        "# Calculate odds accuracy\n",
        "cleaned_matches_data_df['odds_accuracy'] = (cleaned_matches_data_df['favorite_binary'] == cleaned_matches_data_df['FTR']).astype(int)\n"
      ],
      "metadata": {
        "id": "kyH_oOBBIYfB"
      },
      "execution_count": null,
      "outputs": [],
      "id": "kyH_oOBBIYfB"
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_recent_form(df, team, num_games=3):\n",
        "    recent_games = df[((df['home_team_name'] == team) | (df['away_team_name'] == team))].tail(num_games)\n",
        "    form = 0\n",
        "    for _, game in recent_games.iterrows():\n",
        "        if game['home_team_name'] == team:\n",
        "            if game['FTR'] == 'H':  # Assuming 'H' represents a home win\n",
        "                form += 1\n",
        "            elif game['FTR'] == 'A':  # Assuming 'A' represents an away win\n",
        "                form -= 1\n",
        "        else:\n",
        "            if game['FTR'] == 'A':  # Away team wins\n",
        "                form += 1\n",
        "            elif game['FTR'] == 'H':  # Home team wins\n",
        "                form -= 1\n",
        "    return form\n",
        "\n",
        "# Applying the function to calculate recent form\n",
        "df['home_team_recent_form'] = df.apply(lambda row: calculate_recent_form(df, row['home_team_name']), axis=1)\n",
        "df['away_team_recent_form'] = df.apply(lambda row: calculate_recent_form(df, row['away_team_name']), axis=1)\n"
      ],
      "metadata": {
        "id": "dDmlv5HsO6Cb"
      },
      "execution_count": null,
      "outputs": [],
      "id": "dDmlv5HsO6Cb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting categorical columns\n",
        "categorical_cols = ['home_team_name', 'away_team_name', 'referee', 'stadium_name', 'league']\n",
        "\n",
        "# Applying one-hot encoding\n",
        "X_train = pd.get_dummies(X_train, columns=categorical_cols)\n",
        "X_test = pd.get_dummies(X_test, columns=categorical_cols)\n",
        "\n",
        "# Aligning columns of train and test set\n",
        "X_train, X_test = X_train.align(X_test, join='inner', axis=1)  # This ensures both sets have the same dummy columns\n"
      ],
      "metadata": {
        "id": "L6mjyrzmPZCG"
      },
      "execution_count": null,
      "outputs": [],
      "id": "L6mjyrzmPZCG"
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHyEHE1TPcE_",
        "outputId": "bdcfdbd4-d16c-4aba-cc49-059c9dce4a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        13\n",
            "           1       1.00      1.00      1.00        13\n",
            "\n",
            "    accuracy                           1.00        26\n",
            "   macro avg       1.00      1.00      1.00        26\n",
            "weighted avg       1.00      1.00      1.00        26\n",
            "\n"
          ]
        }
      ],
      "id": "eHyEHE1TPcE_"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Ie9Cw7ZMO1R"
      },
      "id": "4Ie9Cw7ZMO1R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting categorical columns\n",
        "categorical_cols = ['home_team_name', 'away_team_name', 'referee', 'stadium_name', 'league']\n",
        "\n",
        "# Applying one-hot encoding to the entire dataset\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_cols)\n",
        "\n",
        "# Now perform cross-validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "model = XGBClassifier()\n",
        "scores = cross_val_score(model, X_encoded, y, cv=5)\n",
        "print(\"Cross-validated scores:\", scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnkksOrNP4cH",
        "outputId": "98b86a18-c0d7-4f8b-fe4f-ccd60950ba27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validated scores: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "id": "mnkksOrNP4cH"
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)  # Make sure X_train and y_train are already defined\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "9o4oM230QiVV",
        "outputId": "8a32f0cf-407c-4342-ef38-5b575fa9e0d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ],
      "id": "9o4oM230QiVV"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aMo8-luMMTHw"
      },
      "id": "aMo8-luMMTHw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = pd.DataFrame(model.feature_importances_,\n",
        "                                   index=X_train.columns,\n",
        "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
        "\n",
        "# Display the feature importances\n",
        "print(feature_importances)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3ukj5gWQlHM",
        "outputId": "194b24d6-3ab9-43e2-c233-13643180e898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     importance\n",
            "goal_difference                             1.0\n",
            "timestamp                                   0.0\n",
            "away_team_name_Olympique Marseille          0.0\n",
            "home_team_name_Union Saint-Gilloise         0.0\n",
            "home_team_name_Villarreal                   0.0\n",
            "...                                         ...\n",
            "over_25_percentage_pre_match                0.0\n",
            "over_15_percentage_pre_match                0.0\n",
            "btts_percentage_pre_match                   0.0\n",
            "average_goals_per_match_pre_match           0.0\n",
            "league_UEFA Europa League                   0.0\n",
            "\n",
            "[136 rows x 1 columns]\n"
          ]
        }
      ],
      "id": "k3ukj5gWQlHM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'favorite_based_on_odds' is the column that shows the expected winner based on odds\n",
        "cleaned_matches_data_df['odds_accuracy'] = (cleaned_matches_data_df['favorite_based_on_odds'] == cleaned_matches_data_df['FTR']).astype(int)\n"
      ],
      "metadata": {
        "id": "oaueZIwvJXmk"
      },
      "execution_count": null,
      "outputs": [],
      "id": "oaueZIwvJXmk"
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_odds_df = cleaned_matches_data_df[cleaned_matches_data_df['odds_accuracy'] == 0]\n",
        "# Perform analysis on 'incorrect_odds_df' to find patterns\n"
      ],
      "metadata": {
        "id": "QdL_qnhlJaYM"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QdL_qnhlJaYM"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}