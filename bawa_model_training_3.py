# -*- coding: utf-8 -*-
"""BAWA_Model Training_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13jgl57jss15QQgdN11ScUmuwRUG5V8oP
"""



"""'''## Model Training and Prediction'''

Model Training and Prediction
(Code for model training and prediction will be added here)
"""



import joblib
import pandas as pd

# Load the model from the file
model_path = '/content/drive/My Drive/94_betting_model/94_betting_model.pkl'  # Update with your correct path
model = joblib.load(model_path)

# Assuming 'combined_leagues_df' is your new data
# And 'selected_features' are the features used by the model
selected_features = ['Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_team_goal_count', 'away_team_goal_count', 'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match', 'odds_ft_home_team_win', 'odds_ft_draw', 'odds_ft_away_team_win']

# Select the features from your new data
X_new = combined_leagues_df[selected_features]

# Check if X_new is empty
if X_new.empty:
    print("The feature DataFrame is empty. Check your data selection process.")
else:
    # Make predictions
    predictions = model.predict(X_new)

    # Add predictions to the DataFrame
    combined_leagues_df['Predicted_FTR'] = predictions

    # Optionally, save the DataFrame with predictions to a new CSV file
    combined_leagues_df.to_csv('/content/drive/My Drive/94_betting_model/predictions3.csv', index=False)

    print("Predictions made and saved successfully.")

import pandas as pd

# Assuming 'combined_leagues_df' is your DataFrame with the features and 'model' is your trained model

# Filter for the dates you're interested in (e.g., Nov 28 and Nov 29, 2023)
dates_of_interest = ['2023-11-28', '2023-11-29']
filtered_df = combined_leagues_df[combined_leagues_df['date_GMT'].isin(dates_of_interest)]

# Extract features for prediction
feature_columns = ['Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_team_goal_count', 'away_team_goal_count', 'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match', 'odds_ft_home_team_win', 'odds_ft_draw', 'odds_ft_away_team_win']
X = filtered_df[feature_columns]

# Make predictions and get probabilities
predicted_results = model.predict(X)
predicted_probabilities = model.predict_proba(X)

# Add predictions and probabilities back to the DataFrame
filtered_df['predicted_result'] = predicted_results
filtered_df['probability_home_win'] = predicted_probabilities[:, 0]  # Probability of Home Win
filtered_df['probability_draw'] = predicted_probabilities[:, 1]      # Probability of Draw
filtered_df['probability_away_win'] = predicted_probabilities[:, 2]  # Probability of Away Win

# Select columns to display
columns_to_display = ['date_GMT', 'home_team_name', 'away_team_name', 'predicted_result', 'probability_home_win', 'probability_draw', 'probability_away_win']
filtered_predictions = filtered_df[columns_to_display]

print(filtered_predictions)

# Assuming 'predictions_df' is your DataFrame with predictions and other relevant columns
predictions_df.to_csv('/content/drive/My Drive/94_betting_model/predictions_2.csv', index=False)

!pip install shap

# Convert 'date_GMT' to datetime
combined_leagues_df['date_GMT'] = pd.to_datetime(combined_leagues_df['date_GMT'])

# Check the range of dates in the dataset
print("Earliest date in the dataset:", combined_leagues_df['date_GMT'].min())
print("Latest date in the dataset:", combined_leagues_df['date_GMT'].max())

# Filter for November 30, 2023
nov_30_predictions = combined_leagues_df[combined_leagues_df['date_GMT'] == pd.Timestamp('2023-11-30')]

# Check if there are any matches on this date
if nov_30_predictions.empty:
    print("No matches found for November 30, 2023.")
else:
    # Extract features and make predictions
    X_nov_30 = nov_30_predictions[feature_columns]
    nov_30_predictions['predicted_result'] = model.predict(X_nov_30)
    nov_30_predictions['predicted_probability'] = model.predict_proba(X_nov_30)[:,1]

    # Display the predictions
    print(nov_30_predictions[['date_GMT', 'home_team_name', 'away_team_name', 'predicted_result', 'predicted_probability']])

"""rhis next code snippet is for searching for dates: chnage this so its easier to update / automate in the future to update ranges based on specific ranges set

"""

# Filter for November 28 and 29, 2023
nov_28_predictions = combined_leagues_df[combined_leagues_df['date_GMT'] == pd.Timestamp('2023-11-28')]
nov_29_predictions = combined_leagues_df[combined_leagues_df['date_GMT'] == pd.Timestamp('2023-11-29')]

# Check if there are any matches on these dates
if nov_28_predictions.empty and nov_29_predictions.empty:
    print("No matches found for November 28 and 29, 2023.")
else:
    # If there are matches on November 28
    if not nov_28_predictions.empty:
        X_nov_28 = nov_28_predictions[feature_columns]
        nov_28_predictions['predicted_result'] = model.predict(X_nov_28)
        nov_28_predictions['predicted_probability'] = model.predict_proba(X_nov_28)[:,1]
        print("Predictions for November 28, 2023:")
        print(nov_28_predictions[['date_GMT', 'home_team_name', 'away_team_name', 'predicted_result', 'predicted_probability']])

    # If there are matches on November 29
    if not nov_29_predictions.empty:
        X_nov_29 = nov_29_predictions[feature_columns]
        nov_29_predictions['predicted_result'] = model.predict(X_nov_29)
        nov_29_predictions['predicted_probability'] = model.predict_proba(X_nov_29)[:,1]
        print("Predictions for November 29, 2023:")
        print(nov_29_predictions[['date_GMT', 'home_team_name', 'away_team_name', 'predicted_result', 'predicted_probability']])

# Filter for November 30, 2023, at specific times
nov_30_545pm_predictions = combined_leagues_df[combined_leagues_df['date_GMT'] == pd.Timestamp('2023-11-30 17:45:00')]
nov_30_800pm_predictions = combined_leagues_df[combined_leagues_df['date_GMT'] == pd.Timestamp('2023-11-30 20:00:00')]

# Check if there are any matches at these times
if nov_30_545pm_predictions.empty and nov_30_800pm_predictions.empty:
    print("No matches found for November 30, 2023, at 5:45 pm and 8:00 pm.")
else:
    # If there are matches at 5:45 pm
    if not nov_30_545pm_predictions.empty:
        X_nov_30_545pm = nov_30_545pm_predictions[feature_columns]
        nov_30_545pm_predictions['predicted_result'] = model.predict(X_nov_30_545pm)
        nov_30_545pm_predictions['predicted_probability'] = model.predict_proba(X_nov_30_545pm)[:,1]
        print("Predictions for November 30, 2023, at 5:45 pm:")
        print(nov_30_545pm_predictions[['date_GMT', 'home_team_name', 'away_team_name', 'predicted_result', 'predicted_probability']])

    # If there are matches at 8:00 pm
    if not nov_30_800pm_predictions.empty:
        X_nov_30_800pm = nov_30_800pm_predictions[feature_columns]
        nov_30_800pm_predictions['predicted_result'] = model.predict(X_nov_30_800pm)
        nov_30_800pm_predictions['predicted_probability'] = model.predict_proba(X_nov_30_800pm)[:,1]
        print("Predictions for November 30, 2023, at 8:00 pm:")
        print(nov_30_800pm_predictions[['date_GMT', 'home_team_name', 'away_team_name', 'predicted_result', 'predicted_probability']])

# Calculate SHAP values using KernelExplainer
explainer = shap.KernelExplainer(model.predict_proba, X)
shap_values = explainer.shap_values(X)

# Plot SHAP values for the first prediction
shap.initjs()
shap.force_plot(explainer.expected_value[1], shap_values[1][0], X.iloc[0])

def calculate_ftr(home_goals, away_goals):
    """
    Calculate the Full Time Result (FTR).
    Home win (0), draw (1), away win (2).
    """
    if home_goals > away_goals:
        return 0  # Home win
    elif home_goals == away_goals:
        return 1  # Draw
    else:
        return 2  # Away win

# Apply the FTR calculation to each row in the DataFrame
combined_leagues_df['FTR'] = combined_leagues_df.apply(
    lambda row: calculate_ftr(row['home_team_goal_count'], row['away_team_goal_count']), axis=1
)

# Selecting the necessary features
selected_features = ['Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_team_goal_count',
                     'away_team_goal_count', 'average_corners_per_match_pre_match',
                     'average_cards_per_match_pre_match', 'odds_ft_home_team_win',
                     'odds_ft_draw', 'odds_ft_away_team_win']

# Assuming 'merged_df' is your preprocessed DataFrame
X = combined_leagues_df[selected_features]

# Assuming 'FTR' is your target variable (full-time result)
y = combined_leagues_df['FTR']





import pandas as pd

# Assuming you have mounted your Google Drive and the path to your files is set correctly
path_to_files = '/content/drive/My Drive/'  # Update this with the correct path

# Load each file into a DataFrame
league_stats_df = pd.read_csv(path_to_files + "europe-uefa-europa-league-league-2023-to-2024-stats.csv")
matches_df = pd.read_csv(path_to_files + "europe-uefa-europa-league-matches-2023-to-2024-stats.csv")
players_df = pd.read_csv(path_to_files + "europe-uefa-europa-league-players-2023-to-2024-stats.csv")
teams_df = pd.read_csv(path_to_files + "europe-uefa-europa-league-teams-2023-to-2024-stats.csv")

# Display the first few rows of each DataFrame to verify
print(league_stats_df.head())
print(matches_df.head())
print(players_df.head())
print(teams_df.head())

# Commented out IPython magic to ensure Python compatibility.
# %whos

matches_df.head()

# Checking for missing values
print("Missing values in matches data:")
print(cleaned_matches_data_df.isnull().sum())

print("\nMissing values in player stats data:")
print(combined_player_stats.isnull().sum())

# Handling missing values - Example: fill with a default value or drop
# cleaned_matches_data_df.fillna(0, inplace=True)
# combined_player_stats.dropna(inplace=True)



"""print(league_stats_df.head()) print(matches_df.head()) print(players_df.head()) print(teams_df.head"""

import pandas as pd

# Assuming the file names are consistent with your upload
cleaned_matches_data_df = pd.read_csv(path_to_files + 'europe-uefa-champions-league-matches-2023-to-2024-stats.csv')
combined_player_stats = pd.read_csv(path_to_files + 'europe-uefa-champions-league-players-2023-to-2024-stats.csv')

import pandas as pd

# Assuming the file names are consistent with your upload
cleaned_matches_data_df = pd.read_csv(path_to_files + 'europe-uefa-europa-league-matches-2023-to-2024-stats.csv')
combined_player_stats = pd.read_csv(path_to_files + 'europe-uefa-europa-league-players-2023-to-2024-stats.csv')

print(cleaned_matches_data_df.head())
print(combined_player_stats.head())

# Checking for missing values
print("Missing values in matches data:")
print(cleaned_matches_data_df.isnull().sum())

print("\nMissing values in player stats data:")
print(combined_player_stats.isnull().sum())

# Handling missing values - Example: fill with a default value or drop
# cleaned_matches_data_df.fillna(0, inplace=True)
# combined_player_stats.dropna(inplace=True)

# Detecting outliers - Example with IQR
Q1 = combined_player_stats.quantile(0.25)
Q3 = combined_player_stats.quantile(0.75)
IQR = Q3 - Q1

# Filtering out the outliers
filtered_player_stats = combined_player_stats[~((combined_player_stats < (Q1 - 1.5 * IQR)) |(combined_player_stats > (Q3 + 1.5 * IQR))).any(axis=1)]

columns_to_remove = ['booked_over05_percentage_overall',
                     'booked_over05_percentage_percentile_overall',
                     'shirt_number',
                     'annual_salary_gbp',
                     'annual_salary_usd']
combined_player_stats.drop(columns=columns_to_remove, inplace=True, errors='ignore')

# Install unidecode
!pip install unidecode

# Import unidecode
import unidecode

# Apply unidecode to standardize player names
combined_player_stats['full_name'] = combined_player_stats['full_name'].apply(unidecode.unidecode)

# Check the changes
print(combined_player_stats.head())

# Dropping specified columns
columns_to_drop = ['attendance', 'booked_over05_percentage_overall',
                   'booked_over05_percentage_percentile_overall',
                   'shirt_number', 'annual_salary_gbp', 'annual_salary_usd']

combined_player_stats.drop(columns=columns_to_drop, inplace=True, errors='ignore')
cleaned_matches_data_df.drop(columns=columns_to_drop, inplace=True, errors='ignore')

# Checking the DataFrame after dropping the columns
print(combined_player_stats.head())
print(cleaned_matches_data_df.head())

# Check the columns of both dataframes
print("Columns in cleaned_matches_data_df:", cleaned_matches_data_df.columns)
print("Columns in combined_player_stats:", combined_player_stats.columns)

# Merging player stats with home team stats
home_merged = pd.merge(cleaned_matches_data_df,
                       combined_player_stats,
                       left_on=['home_team_name', 'season'],
                       right_on=['Current Club', 'season'])

# Merging player stats with away team stats
away_merged = pd.merge(cleaned_matches_data_df,
                       combined_player_stats,
                       left_on=['away_team_name', 'season'],
                       right_on=['Current Club', 'season'])



print("Columns in cleaned_matches_data_df:", cleaned_matches_data_df.columns.tolist())
print("Columns in combined_player_stats:", combined_player_stats.columns.tolist())

# Assuming 'Current Club' and 'league' are the columns in players dataframe
team_league_mapping = combined_player_stats[['Current Club', 'league']].drop_duplicates()
team_league_mapping = team_league_mapping.set_index('Current Club')['league'].to_dict()

# Function to get league from team name
def get_league(team_name):
    return team_league_mapping.get(team_name, "Unknown")

# Apply the function to the matches dataframe
cleaned_matches_data_df['league'] = cleaned_matches_data_df['home_team_name'].apply(get_league)

# Check for matches with 'Unknown' league
unknown_league_matches = cleaned_matches_data_df[cleaned_matches_data_df['league'] == "Unknown"]
print(unknown_league_matches)

"""Results Visualization Visualize the results of the model.

Double-click (or enter) to edit
"""

import pandas as pd

# Example: Aggregating player stats for a team in a particular match
# Let's say you have a function that takes a team name and a date and returns the aggregated stats for that team
def get_team_stats_for_match(team_name, match_date, player_stats_df):
    # Filter player stats for the given team and date
    # Aggregate stats as needed (e.g., average rating, total goals)
    # Return aggregated stats as a pandas Series or DataFrame row
    pass

# Loop through each match in the match data
for index, row in cleaned_matches_data_df.iterrows():
    # Get team names and match date
    home_team = row['home_team_name']
    away_team = row['away_team_name']
    match_date = row['date_GMT']

    # Get aggregated stats for both teams
    home_team_stats = get_team_stats_for_match(home_team, match_date, combined_player_stats)
    away_team_stats = get_team_stats_for_match(away_team, match_date, combined_player_stats)

    # Merge these stats into the match data row
    # This can be done by setting new columns in 'row' or by merging Series/DataFrames

# Now 'cleaned_matches_data_df' will have additional columns for each team's player stats

# Function to calculate form
def calculate_form(df, num_matches):
    form = []
    for team in df['home_team_name'].unique():
        team_matches = df[(df['home_team_name'] == team) | (df['away_team_name'] == team)]
        team_matches = team_matches.sort_values('date_GMT').tail(num_matches)
        team_form = 0
        for index, row in team_matches.iterrows():
            if row['home_team_name'] == team:
                if row['home_team_goal_count'] > row['away_team_goal_count']:
                    team_form += 3  # Win
                elif row['home_team_goal_count'] == row['away_team_goal_count']:
                    team_form += 1  # Draw
            elif row['away_team_name'] == team:
                if row['away_team_goal_count'] > row['home_team_goal_count']:
                    team_form += 3  # Win
                elif row['away_team_goal_count'] == row['home_team_goal_count']:
                    team_form += 1  # Draw
        form.append({'team': team, 'form': team_form})
    return pd.DataFrame(form)

# Calculate form for teams
team_form_df = calculate_form(cleaned_matches_data_df, 5)

# Function to calculate form
def calculate_form(df, num_matches):
    form = []
    for team in df['away_team_name'].unique():
        team_matches = df[(df['home_team_name'] == team) | (df['away_team_name'] == team)]
        team_matches = team_matches.sort_values('date_GMT').tail(num_matches)
        team_form = 0
        for index, row in team_matches.iterrows():
            if row['home_team_name'] == team:
                if row['home_team_goal_count'] > row['away_team_goal_count']:
                    team_form += 3  # Win
                elif row['home_team_goal_count'] == row['away_team_goal_count']:
                    team_form += 1  # Draw
            elif row['away_team_name'] == team:
                if row['away_team_goal_count'] > row['home_team_goal_count']:
                    team_form += 3  # Win
                elif row['away_team_goal_count'] == row['home_team_goal_count']:
                    team_form += 1  # Draw
        form.append({'team': team, 'form': team_form})
    return pd.DataFrame(form)

# Calculate form for teams
team_form_df = calculate_form(cleaned_matches_data_df, 5)

def head_to_head_stats(df, team1, team2):
    matches = df[((df['home_team_name'] == team1) & (df['away_team_name'] == team2)) |
                 ((df['home_team_name'] == team2) & (df['away_team_name'] == team1))]
    # Perform calculations to find head-to-head stats
    # ...

# Example usage
head_to_head_stats(cleaned_matches_data_df, 'Team A', 'Team B')

team_form_df['form_average'] = team_form_df['form'] / 5  # Assuming 5 is the number of matches considered for form

def create_ftr_column(df):
    df['FTR'] = df.apply(lambda row: 0 if row['home_team_goal_count'] > row['away_team_goal_count'] else 1, axis=1)

create_ftr_column(cleaned_matches_data_df)

# Display the first few rows of the DataFrame
print(cleaned_matches_data_df.head())

# Replace 'Team A' and 'Team B' with actual team names
sample_teams = cleaned_matches_data_df[(cleaned_matches_data_df['home_team_name'] == 'Manchester City') |
                                       (cleaned_matches_data_df['away_team_name'] == 'Liverpool')]
print(sample_teams[['home_team_name', 'away_team_name', 'FTR',]])

# Print all column names
print(cleaned_matches_data_df.columns)



# Check if 'form' column exists
if 'form' in cleaned_matches_data_df.columns:
    print("Column 'form' exists in the DataFrame.")
else:
    print("Column 'form' does not exist in the DataFrame.")

try:
    form_column = cleaned_matches_data_df['form']
    print("Column 'form' exists.")
except KeyError:
    print("Column 'form' does not exist.")

def calculate_form(df, team_name, n_matches=5):
    """
    Calculate the form of a team over the last n matches.
    """
    recent_matches = df[df['home_team_name'] == team_name].tail(n_matches)
    points = 0
    for index, row in recent_matches.iterrows():
        if row['home_team_goal_count'] > row['away_team_goal_count']:
            points += 3  # Home win
        elif row['home_team_goal_count'] == row['away_team_goal_count']:
            points += 1  # Draw
    return points / (3 * n_matches)  # Return the average points per match

# Calculate form for each team and each match
cleaned_matches_data_df['home_team_form'] = cleaned_matches_data_df.apply(
    lambda row: calculate_form(cleaned_matches_data_df, row['home_team_name']), axis=1)

cleaned_matches_data_df['away_team_form'] = cleaned_matches_data_df.apply(
    lambda row: calculate_form(cleaned_matches_data_df, row['away_team_name']), axis=1)

def calculate_head_to_head_stats(df, home_team, away_team):
    """
    Calculate head-to-head statistics between two teams.
    """
    # Filter matches where either team was playing at home against the other
    head_to_head_matches = df[((df['home_team_name'] == home_team) & (df['away_team_name'] == away_team)) |
                              ((df['home_team_name'] == away_team) & (df['away_team_name'] == home_team))]

    # Calculate stats like number of wins, draws, losses, goals scored, etc.
    home_wins = len(head_to_head_matches[(head_to_head_matches['home_team_name'] == home_team) &
                                         (head_to_head_matches['home_team_goal_count'] > head_to_head_matches['away_team_goal_count'])])
    away_wins = len(head_to_head_matches[(head_to_head_matches['home_team_name'] == away_team) &
                                         (head_to_head_matches['home_team_goal_count'] < head_to_head_matches['away_team_goal_count'])])
    draws = len(head_to_head_matches[head_to_head_matches['home_team_goal_count'] == head_to_head_matches['away_team_goal_count']])

    # Return a dictionary of stats
    return {
        'home_wins': home_wins,
        'away_wins': away_wins,
        'draws': draws
    }

# Apply the function to each match
cleaned_matches_data_df['head_to_head'] = cleaned_matches_data_df.apply(
    lambda row: calculate_head_to_head_stats(cleaned_matches_data_df, row['home_team_name'], row['away_team_name']), axis=1)



def calculate_ftr(home_goals, away_goals):
    if home_goals > away_goals:
        return 0  # Home win
    else:
        return 1  # Draw or Away win

cleaned_matches_data_df['FTR'] = cleaned_matches_data_df.apply(
    lambda row: calculate_ftr(row['home_team_goal_count'], row['away_team_goal_count']), axis=1)

# Optionally, save your DataFrame to a CSV file
cleaned_matches_data_df.to_csv('/content/cleaned_matches_data_with_features.csv', index=False)

# Assuming you have already loaded cleaned_matches_data_df
print(cleaned_matches_data_df.describe())

# Histograms for continuous variables in matches data
cleaned_matches_data_df[['home_team_goal_count', 'away_team_goal_count']].hist(bins=15, figsize=(15, 6))

# Scatter Plot for relationships in matches data
plt.scatter(cleaned_matches_data_df['home_team_shots'], cleaned_matches_data_df['home_team_goal_count'])
plt.xlabel('Home Team Shots')
plt.ylabel('Home Team Goals')
plt.title('Home Team Shots vs Goals')

# Correlation Heatmap for matches data
corr_matches = cleaned_matches_data_df.corr()
plt.figure(figsize=(10,10))
sns.heatmap(corr_matches, annot=True, fmt=".2f")

# Assuming you have already loaded combined_player_stats
print(combined_player_stats.describe())

# Histograms for continuous variables in player stats
combined_player_stats[['age', 'minutes_played_overall', 'goals_per_90_overall']].hist(bins=15, figsize=(15, 6))

# Scatter Plot for relationships in player stats
plt.scatter(combined_player_stats['goals_overall'], combined_player_stats['assists_overall'])
plt.xlabel('Goals')
plt.ylabel('Assists')
plt.title('Goals vs Assists in Player Stats')

# Correlation Heatmap for player stats
corr_players = combined_player_stats.corr()
plt.figure(figsize=(10,10))
sns.heatmap(corr_players, annot=True, fmt=".2f")

cleaned_matches_data_df['FTR'] = (cleaned_matches_data_df['home_team_goal_count'] <= cleaned_matches_data_df['away_team_goal_count']).astype(int)

# Assuming 'combined_player_stats' is your DataFrame with player stats
shot_related_columns = [col for col in combined_player_stats.columns if 'shot' in col.lower()]
print(shot_related_columns)

# Handling division by zero
combined_player_stats['shot_efficiency'] = combined_player_stats.apply(
    lambda row: row['goals_overall'] / row['shots_total_overall'] if row['shots_total_overall'] > 0 else 0, axis=1
)

# Shot Efficiency
combined_player_stats['shot_efficiency'] = combined_player_stats['goals_overall'] / combined_player_stats['shots_total_overall']

# Shots on Target Rate
combined_player_stats['shots_on_target_rate'] = combined_player_stats['shots_on_target_total_overall'] / combined_player_stats['shots_total_overall']

# Conversion Rate
combined_player_stats['conversion_rate'] = combined_player_stats['goals_overall'] / combined_player_stats['shots_on_target_total_overall']

# Shooting Accuracy
combined_player_stats['shooting_accuracy'] = combined_player_stats['shots_on_target_total_overall'] / combined_player_stats['shots_total_overall']

# Defensive Pressure
combined_player_stats['defensive_pressure'] = combined_player_stats['shots_faced_total_overall'] / combined_player_stats['appearances_overall']

# Goalkeeping Performance
# Assuming 'goals_conceded_overall' is the number of goals a goalkeeper has conceded
combined_player_stats['goalkeeper_performance'] = combined_player_stats['conceded_per_90_overall'] / combined_player_stats['shots_faced_total_overall']

# Long-Shot Specialist
combined_player_stats['long_shot_specialist'] = combined_player_stats['shots_total_overall'] - combined_player_stats['shots_on_target_total_overall']

# Shot Conversion Rate Standardized
shot_conversion_mean = combined_player_stats['shot_conversion_rate_overall'].mean()
shot_conversion_std = combined_player_stats['shot_conversion_rate_overall'].std()
combined_player_stats['shot_conversion_rate_standardized'] = (combined_player_stats['shot_conversion_rate_overall'] - shot_conversion_mean) / shot_conversion_std

# Before running this code, ensure that there are no divisions by zero and handle any NaN values that may result from these computations.

print(combined_player_stats.columns)

features = ['Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_team_goal_count', 'away_team_goal_count', 'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match', 'odds_ft_home_team_win', 'odds_ft_draw', 'odds_ft_away_team_win']



# Selecting features - example features selected here
features = df[['Pre-Match PPG (Home)', 'Pre-Match PPG (Away)', 'home_ppg', 'away_ppg',
               'Home Team Pre-Match xG', 'Away Team Pre-Match xG',
               'average_goals_per_match_pre_match', 'btts_percentage_pre_match',
               'over_15_percentage_pre_match', 'over_25_percentage_pre_match',
               'average_corners_per_match_pre_match', 'average_cards_per_match_pre_match',
               'odds_ft_home_team_win', 'odds_ft_draw', 'odds_ft_away_team_win',
               'league', 'home_team_form', 'away_team_form', 'head_to_head']]

# Target variable
target = df['FTR']

# Checking the selected features and target
print("Selected Features Sample:")
print(features.head())

print("\nTarget Variable Sample:")
print(target.head())



"""ADJUST DATE HERE FOR SPECIFIC SEARCH:"""

# Check if 'date' column exists in the DataFrame
if 'date_GMT' in df.columns:
    print("Column 'date_GMT' exists.")
else:
    print("Column 'date_GMT' does not exist.")

# Example: Sorting data by date instead of timestamp
df.sort_values(by='date_GMT', inplace=True)

# Example: Splitting data based on a specific date
train_df = df[df['date_GMT'] < '2023-11-30']
test_df = df[df['date_GMT'] >= '2023-11-30']



if 'head_to_head' in df.columns:
    print("Column 'head_to_head' exists.")
else:
    print("Column 'head_to_head' does not exist.")

# Assuming you have a function that can calculate head to head statistics
def calculate_head_to_head(home_team, away_team):
    # This function would return head to head stats like {'home_wins': X, 'away_wins': Y, 'draws': Z}
    # based on historical data of matches between the two teams.
    pass

# Apply the function to each row in the DataFrame
df['head_to_head'] = df.apply(lambda row: calculate_head_to_head(row['home_team_name'], row['away_team_name']), axis=1)

# Update categorical and numeric features
categorical_features = ['league']
numeric_features = [col for col in df.columns if col not in categorical_features + ['head_to_head']]

# Proceed with your preprocessing steps as before

# Display the first few rows of the DataFrame
print("First few rows of the DataFrame:")
print(df.head())

# Display summary statistics of the DataFrame
print("\nSummary Statistics:")
print(df.describe())

# Display the data types of each column
print("\nData Types:")
print(df.dtypes)



df['goal_difference'] = df['home_team_goal_count'] - df['away_team_goal_count']

df['combined_team_form'] = (df['home_team_form'] + df['away_team_form']) / 2

df['date_GMT'] = pd.to_datetime(df['date_GMT'])
df['day_of_week'] = df['date_GMT'].dt.day_name()
df['time_of_day'] = df['date_GMT'].dt.hour

df['date_GMT'] = pd.to_datetime(df['date_GMT'])

print(df.columns)



cutoff_date = pd.Timestamp('2023-11-30')
train_data = df[df['date_GMT'] < cutoff_date]
test_data = df[df['date_GMT'] >= cutoff_date]

X_train = train_data.drop('FTR', axis=1)
y_train = train_data['FTR']
X_test = test_data.drop('FTR', axis=1)
y_test = test_data['FTR']

X_train = train_data.drop('FTR', axis=1)
y_train = train_data['FTR']
X_test = test_data.drop('FTR', axis=1)
y_test = test_data['FTR']



from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

X = cleaned_matches_data_df[features]
y = cleaned_matches_data_df['FTR']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(f"Accuracy: {accuracy_score(y_test, y_pred)}")

df_encoded = pd.get_dummies(df, columns=['home_team_name', 'away_team_name', 'league', 'referee', 'stadium_name'])

df = df.drop(['date_GMT', 'home_team_goal_timings', 'away_team_goal_timings', 'head_to_head'], axis=1)

df = pd.get_dummies(df, columns=['status', 'day_of_week'])



# Commented out IPython magic to ensure Python compatibility.
# %whos



from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=5)
print(f"Cross-validated scores: {scores}")

# Assuming 'favorite_based_on_odds' is the column that shows the expected winner based on odds
cleaned_matches_data_df['odds_accuracy'] = (cleaned_matches_data_df['favorite_based_on_odds'] == cleaned_matches_data_df['FTR']).astype(int)



categorical_columns = ['home_team_name', 'away_team_name', 'referee', 'stadium_name', 'league']
X_train = pd.get_dummies(X_train, columns=categorical_columns)

print(df.columns)

def determine_favorite(row):
    home_odds = row['odds_ft_home_team_win']
    draw_odds = row['odds_ft_draw']
    away_odds = row['odds_ft_away_team_win']

    if min(home_odds, draw_odds, away_odds) == home_odds:
        return 'Home'
    elif min(home_odds, draw_odds, away_odds) == away_odds:
        return 'Away'
    else:
        return 'Draw'

# Apply the function to each row
cleaned_matches_data_df['favorite_based_on_odds'] = cleaned_matches_data_df.apply(determine_favorite, axis=1)

from xgboost import XGBClassifier

# Initialize the model
model = XGBClassifier()

# Fit the model to your training data
model.fit(X_train, y_train)



print(X_test.dtypes)

y_pred = model.predict(X_test)

# Proceed with evaluating the model

from xgboost import XGBClassifier

# Initialize the model
model = XGBClassifier()

# Fit the model to your training data
model.fit(X_train, y_train)

# Making predictions
y_pred = model.predict(X_test)

# Evaluating the model
from sklearn.metrics import accuracy_score, classification_report

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:")
print(classification_report(y_test, y_pred))



# Converting to Unix timestamp
X['date_GMT'] = X['date_GMT'].astype(int) / 10**9

object_columns = ['status', 'home_team_goal_timings', 'away_team_goal_timings', 'head_to_head', 'day_of_week']
X = pd.get_dummies(X, columns=object_columns)

from sklearn.model_selection import cross_val_score

model = XGBClassifier(enable_categorical=True)
scores = cross_val_score(model, X, y, cv=5, error_score='raise')
print("Cross-validated scores:", scores)
print("Average score:", scores.mean())

from xgboost import XGBClassifier

model = XGBClassifier()  # Replace with your model and parameters
print(model)

print(df.describe(include='all'))

from sklearn.metrics import classification_report, confusion_matrix

# Assuming y_test and y_pred are your test labels and model predictions
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=5)  # Replace X and y with your features and labels
print("Cross-validation scores:", scores)

print("Dataset shape:", df.shape)
print("Dataset info:")
print(df.info())

# Example: Comparing training and validation accuracy
train_accuracy = ...  # Your training accuracy
validation_accuracy = ...  # Your validation accuracy
print("Training accuracy:", train_accuracy)
print("Validation accuracy:", validation_accuracy)

from xgboost import XGBClassifier

model = XGBClassifier()  # Replace with your specific model parameters
model.fit(X_train, y_train)

import pandas as pd

# Assuming df is your original DataFrame
# And it has columns like 'home_team_name', 'away_team_name', 'match_outcome'

# Initialize columns
df['home_team_recent_form'] = 0
df['away_team_recent_form'] = 0

# Iterate and calculate form (example for home team)
for index, row in df.iterrows():
    # Get last 3-5 matches for the home team
    recent_matches = df[(df['home_team_name'] == row['home_team_name']) & (df.index < index)].tail(3)

    # Calculate wins, draws, and losses
    wins = len(recent_matches[recent_matches['FTR'] == 'Win'])
    draws = len(recent_matches[recent_matches['FTR'] == 'Draw'])
    losses = len(recent_matches[recent_matches['FTR'] == 'Loss'])

    # Assign to the new column
    df.at[index, 'home_team_recent_form'] = wins - losses  # Example formula

# Repeat similar steps for the away team

feature_importances = pd.DataFrame(model.feature_importances_,
                                   index=X_train.columns,
                                   columns=['importance']).sort_values('importance', ascending=False)
print(feature_importances)

import pandas as pd

# Assuming df is your DataFrame
print(df.columns)



"""above is the features of the cleaned matches data df.csv"""

was the features we want to drop

"""next is the features we want to drop"""

# Assuming 'df' is your DataFrame

# List of features to drop
features_to_drop = ['timestamp', 'home_team_name', 'away_team_name', 'referee',
                    'stadium_name', 'league', 'status_complete', 'status_incomplete',
                    'day_of_week_Thursday', 'day_of_week_Tuesday']

# Drop the features
df = df.drop(features_to_drop, axis=1)

# Define your features (X) and target variable (y)
X = df.drop('FTR', axis=1)  # Replace 'FTR' with your actual target column name if different
y = df['FTR']



from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from xgboost import XGBClassifier

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Training the model
model = XGBClassifier()
model.fit(X_train, y_train)

# Making predictions and evaluating the model
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

from sklearn.model_selection import cross_val_score

# Using cross-validation to assess model performance
scores = cross_val_score(model, X, y, cv=5)
print("Cross-validated scores:", scores)

feature_importances = pd.DataFrame(model.feature_importances_,
                                   index=X_train.columns,
                                   columns=['importance']).sort_values('importance', ascending=False)
print(feature_importances)

# Assuming feature_importances is your DataFrame with feature importances
zero_importance_features = feature_importances[feature_importances['importance'] == 0].index

# Drop these features from your dataset
X = X.drop(zero_importance_features, axis=1)



scores = cross_val_score(model, X, y, cv=5)
print("Cross-validated scores:", scores)

# Calculating average possession for home teams
df['average_home_possession'] = df.groupby('home_team_name')['home_team_possession'].transform('mean')

# Calculating average possession for away teams
df['average_away_possession'] = df.groupby('away_team_name')['away_team_possession'].transform('mean')



import pandas as pd

file_path = '/content/cleaned_matches_data_df.csv'  # Update with your file's path
df = pd.read_csv(file_path)

# Display the first few rows of the DataFrame
print(df.head())

# Display DataFrame information
print(df.info())

# Check summary statistics
print(df.describe())

# Fill NA values in 'date_GMT' with a placeholder
df['date_GMT'].fillna('No Date', inplace=True)

# Filter for matches on November 28th and 29th, 2023
matches_nov_28_29 = df[df['date_GMT'].str.contains('Nov 28 2023|Nov 29 2023')]

# Commented out IPython magic to ensure Python compatibility.
# List only the variables that are DataFrames
# %whos DataFrame

